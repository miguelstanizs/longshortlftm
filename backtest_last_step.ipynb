{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8186c56",
   "metadata": {},
   "source": [
    "CALCULA OS PESOS DO PORTFÓLIO NOS INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "94be9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custo_rebalanceamento = 0.0003\n",
    "custo_ajuste = 0.0005\n",
    "data_escolhida = '2020-09-02'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d97b35",
   "metadata": {},
   "source": [
    "Preços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1efd50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame SMAL11 (df_perf_smal):\n",
      "              SMAL11\n",
      "Data                \n",
      "2019-09-02  0.000000\n",
      "2019-09-03 -0.009009\n",
      "2019-09-04 -0.003636\n",
      "2019-09-05  0.005474\n",
      "2019-09-06 -0.010436\n",
      "...              ...\n",
      "2025-03-25  0.014917\n",
      "2025-03-26  0.005774\n",
      "2025-03-27  0.005324\n",
      "2025-03-28 -0.009449\n",
      "2025-03-31 -0.020755\n",
      "\n",
      "[1456 rows x 1 columns]\n",
      "\n",
      "DataFrame IBOV (df_perf_ibov):\n",
      "                IBOV\n",
      "Data                \n",
      "2019-09-02  0.000000\n",
      "2019-09-03 -0.008888\n",
      "2019-09-04  0.015328\n",
      "2019-09-05  0.010989\n",
      "2019-09-06  0.007009\n",
      "...              ...\n",
      "2025-03-25  0.006631\n",
      "2025-03-26  0.001550\n",
      "2025-03-27  0.004178\n",
      "2025-03-28 -0.008399\n",
      "2025-03-31 -0.010801\n",
      "\n",
      "[1456 rows x 1 columns]\n",
      "\n",
      "DataFrame com tickers de empresas (df_perf):\n",
      "               TGMA3     ARML3     VAMO3     ALPA4     AZZA3     ASAI3  \\\n",
      "Data                                                                     \n",
      "2019-09-02  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2019-09-03 -0.023038  0.000000  0.000000 -0.030091 -0.012443  0.000000   \n",
      "2019-09-04  0.011022  0.000000  0.000000 -0.004617  0.010285  0.000000   \n",
      "2019-09-05 -0.009000  0.000000  0.000000 -0.006329  0.007080  0.000000   \n",
      "2019-09-06 -0.019230  0.000000  0.000000 -0.025390 -0.009098  0.000000   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2025-03-25  0.009944 -0.020534  0.156177  0.029369 -0.005019  0.011984   \n",
      "2025-03-26 -0.025775  0.008386  0.062500  0.012839  0.018495  0.052632   \n",
      "2025-03-27 -0.008323 -0.004158 -0.022770 -0.011268  0.031779  0.003750   \n",
      "2025-03-28  0.000899 -0.154489 -0.093204  0.001425 -0.013200 -0.018680   \n",
      "2025-03-31  0.007787 -0.069136 -0.059957 -0.025605 -0.006891 -0.043147   \n",
      "\n",
      "               CEAB3     CRFB3     ESPA3     GGPS3  ...    TAEE11    ALUP11  \\\n",
      "Data                                                ...                       \n",
      "2019-09-02  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
      "2019-09-03  0.000000 -0.004958  0.000000  0.000000  ...  0.000674 -0.014031   \n",
      "2019-09-04  0.000000 -0.001812  0.000000  0.000000  ...  0.017883  0.014602   \n",
      "2019-09-05  0.000000 -0.010841  0.000000  0.000000  ... -0.003490  0.008530   \n",
      "2019-09-06  0.000000 -0.014222  0.000000  0.000000  ... -0.001449 -0.002283   \n",
      "...              ...       ...       ...       ...  ...       ...       ...   \n",
      "2025-03-25  0.040658 -0.004038  0.014493  0.010226  ... -0.012518  0.002386   \n",
      "2025-03-26  0.034419 -0.002703  0.000000 -0.013015  ...  0.002358 -0.002720   \n",
      "2025-03-27  0.013489  0.012195  0.042857  0.019780  ... -0.002647  0.007842   \n",
      "2025-03-28 -0.020408 -0.014726  0.000000 -0.007902  ...  0.001180 -0.005413   \n",
      "2025-03-31 -0.038043 -0.014946 -0.027397 -0.055033  ... -0.008542 -0.011565   \n",
      "\n",
      "               AZUL4     UNIP6     ORVR3     AMBP3     CVCB3     TASA4  \\\n",
      "Data                                                                     \n",
      "2019-09-02  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2019-09-03 -0.025032  0.002324  0.000000  0.000000 -0.008564  0.011263   \n",
      "2019-09-04  0.025022  0.052097  0.000000  0.000000 -0.019540  0.008775   \n",
      "2019-09-05  0.044789 -0.006416  0.000000  0.000000 -0.007655 -0.011375   \n",
      "2019-09-06  0.002641  0.012264  0.000000  0.000000 -0.018726  0.014213   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2025-03-25 -0.008287  0.004074  0.016002 -0.003719  0.066038  0.014888   \n",
      "2025-03-26 -0.022284 -0.011435 -0.022598 -0.080382  0.030973  0.012225   \n",
      "2025-03-27 -0.002849  0.034328  0.015880  0.074238 -0.025751  0.006039   \n",
      "2025-03-28 -0.017143 -0.009199 -0.019080  0.008481 -0.004405 -0.008403   \n",
      "2025-03-31 -0.043605 -0.001274 -0.008671  0.022814 -0.061947 -0.014528   \n",
      "\n",
      "               GOLL4     EMBR3  \n",
      "Data                            \n",
      "2019-09-02  0.000000  0.000000  \n",
      "2019-09-03 -0.033088  0.009599  \n",
      "2019-09-04  0.013942  0.009508  \n",
      "2019-09-05  0.062812  0.019391  \n",
      "2019-09-06  0.001470 -0.021196  \n",
      "...              ...       ...  \n",
      "2025-03-25  0.006944 -0.021193  \n",
      "2025-03-26  0.006897 -0.005879  \n",
      "2025-03-27  0.000000 -0.014568  \n",
      "2025-03-28 -0.041096 -0.028689  \n",
      "2025-03-31 -0.014286 -0.009192  \n",
      "\n",
      "[1456 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega o arquivo Excel para um DataFrame\n",
    "df_precos = pd.read_excel('precos.xlsx', index_col = 0)\n",
    "\n",
    "# Cria um DataFrame para os retornos dos ativos\n",
    "df_perf = df_precos.copy()\n",
    "\n",
    "# Calcula os retornos dos ativos\n",
    "for coluna in df_precos.columns:\n",
    "    df_perf[coluna] = df_precos[coluna] / df_precos[coluna].shift(1) - 1\n",
    "\n",
    "# Substitui a primeira linha por zeros\n",
    "df_perf.iloc[0] = 0\n",
    "\n",
    "# Substitui os valores NaN por zeros\n",
    "df_perf.fillna(0, inplace=True)\n",
    "\n",
    "# Isola SMAL11 em df_perf_smal\n",
    "df_perf_smal = df_perf[['SMAL11']].copy()\n",
    "\n",
    "# Isola IBOV em df_perf_ibov\n",
    "df_perf_ibov = df_perf[['IBOV']].copy()\n",
    "\n",
    "# Remove SMAL11 e IBOV de df_perf\n",
    "df_perf = df_perf.drop(columns=['SMAL11', 'IBOV'])\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"DataFrame SMAL11 (df_perf_smal):\")\n",
    "print(df_perf_smal)\n",
    "print(\"\\nDataFrame IBOV (df_perf_ibov):\")\n",
    "print(df_perf_ibov)\n",
    "print(\"\\nDataFrame com tickers de empresas (df_perf):\")\n",
    "print(df_perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "37b8e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame com retornos diários do CDI (df_perf_cdi):\n",
      "                 CDI\n",
      "Data                \n",
      "2019-09-02  1.000228\n",
      "2019-09-03  1.000228\n",
      "2019-09-04  1.000228\n",
      "2019-09-05  1.000228\n",
      "2019-09-06  1.000228\n",
      "...              ...\n",
      "2025-03-25  1.000525\n",
      "2025-03-26  1.000525\n",
      "2025-03-27  1.000525\n",
      "2025-03-28  1.000525\n",
      "2025-03-31  1.000525\n",
      "\n",
      "[1456 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega o arquivo hist_cdi.xlsx para um DataFrame\n",
    "df_perf_cdi = pd.read_excel('hist_cdi.xlsx',index_col= 0)\n",
    "\n",
    "# Exibe os dados carregados\n",
    "print(\"DataFrame com retornos diários do CDI (df_perf_cdi):\")\n",
    "print(df_perf_cdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a150a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame taxas short do SMAL11 (df_taxa_short_smal):\n",
      "            SMAL11\n",
      "Data              \n",
      "2019-09-02  0.0107\n",
      "2019-09-03  0.0093\n",
      "2019-09-04  0.0075\n",
      "2019-09-05  0.0160\n",
      "2019-09-06  0.0062\n",
      "...            ...\n",
      "2025-03-25  0.0884\n",
      "2025-03-26  0.0884\n",
      "2025-03-27  0.0884\n",
      "2025-03-28  0.0884\n",
      "2025-03-31  0.0884\n",
      "\n",
      "[1456 rows x 1 columns]\n",
      "\n",
      "DataFrame taxas short do IBOV (df_taxa_short_ibov):\n",
      "              IBOV\n",
      "Data              \n",
      "2019-09-02  0.0164\n",
      "2019-09-03  0.0132\n",
      "2019-09-04  0.0127\n",
      "2019-09-05  0.0128\n",
      "2019-09-06  0.0140\n",
      "...            ...\n",
      "2025-03-25  0.0115\n",
      "2025-03-26  0.0115\n",
      "2025-03-27  0.0115\n",
      "2025-03-28  0.0115\n",
      "2025-03-31  0.0115\n",
      "\n",
      "[1456 rows x 1 columns]\n",
      "\n",
      "DataFrame com taxas short dos papéis (df_taxas_short):\n",
      "             TGMA3   ARML3   VAMO3   ALPA4   AZZA3   ASAI3   CEAB3   CRFB3  \\\n",
      "Data                                                                         \n",
      "2019-09-02  0.0026  0.0000  0.0000  0.0033  0.0111  0.0000  0.0000  0.0060   \n",
      "2019-09-03  0.0033  0.0000  0.0000  0.0089  0.0143  0.0000  0.0000  0.0069   \n",
      "2019-09-04  0.0042  0.0000  0.0000  0.0091  0.0155  0.0000  0.0000  0.0063   \n",
      "2019-09-05  0.0025  0.0000  0.0000  0.0086  0.0150  0.0000  0.0000  0.0055   \n",
      "2019-09-06  0.0008  0.0000  0.0000  0.0082  0.0146  0.0000  0.0000  0.0056   \n",
      "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "2025-03-25  0.0341  0.0082  0.1111  0.0061  0.0096  0.0174  0.0051  0.0180   \n",
      "2025-03-26  0.0341  0.0082  0.1111  0.0061  0.0096  0.0174  0.0051  0.0180   \n",
      "2025-03-27  0.0341  0.0082  0.1111  0.0061  0.0096  0.0174  0.0051  0.0180   \n",
      "2025-03-28  0.0341  0.0082  0.1111  0.0061  0.0096  0.0174  0.0051  0.0180   \n",
      "2025-03-31  0.0341  0.0082  0.1111  0.0061  0.0096  0.0174  0.0051  0.0180   \n",
      "\n",
      "             ESPA3   GGPS3  ...  TAEE11  ALUP11   AZUL4   UNIP6   ORVR3  \\\n",
      "Data                        ...                                           \n",
      "2019-09-02  0.0000  0.0000  ...  0.0014  0.0013  0.0011  0.0020  0.0000   \n",
      "2019-09-03  0.0000  0.0000  ...  0.0017  0.0023  0.0013  0.0018  0.0000   \n",
      "2019-09-04  0.0000  0.0000  ...  0.0019  0.0015  0.0017  0.0016  0.0000   \n",
      "2019-09-05  0.0000  0.0000  ...  0.0013  0.0017  0.0019  0.0023  0.0000   \n",
      "2019-09-06  0.0000  0.0000  ...  0.0007  0.0027  0.0016  0.0116  0.0000   \n",
      "...            ...     ...  ...     ...     ...     ...     ...     ...   \n",
      "2025-03-25  0.0164  0.0034  ...  0.0030  0.0037  0.3111  0.0033  0.0271   \n",
      "2025-03-26  0.0164  0.0034  ...  0.0030  0.0037  0.3111  0.0033  0.0271   \n",
      "2025-03-27  0.0164  0.0034  ...  0.0030  0.0037  0.3111  0.0033  0.0271   \n",
      "2025-03-28  0.0164  0.0034  ...  0.0030  0.0037  0.3111  0.0033  0.0271   \n",
      "2025-03-31  0.0164  0.0034  ...  0.0030  0.0037  0.3111  0.0033  0.0271   \n",
      "\n",
      "             AMBP3   CVCB3   TASA4   GOLL4   EMBR3  \n",
      "Data                                                \n",
      "2019-09-02  0.0000  0.0023  0.0231  0.0132  0.0014  \n",
      "2019-09-03  0.0000  0.0021  0.0169  0.0208  0.0014  \n",
      "2019-09-04  0.0000  0.0024  0.0047  0.0177  0.0015  \n",
      "2019-09-05  0.0000  0.0027  0.0085  0.0128  0.0011  \n",
      "2019-09-06  0.0000  0.0035  0.0055  0.0210  0.0019  \n",
      "...            ...     ...     ...     ...     ...  \n",
      "2025-03-25  0.0141  0.1491  0.0038  0.0785  0.0014  \n",
      "2025-03-26  0.0141  0.1491  0.0038  0.0785  0.0014  \n",
      "2025-03-27  0.0141  0.1491  0.0038  0.0785  0.0014  \n",
      "2025-03-28  0.0141  0.1491  0.0038  0.0785  0.0014  \n",
      "2025-03-31  0.0141  0.1491  0.0038  0.0785  0.0014  \n",
      "\n",
      "[1456 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega o arquivo taxas_short.xlsx para um DataFrame\n",
    "df_taxas_short = pd.read_excel('taxas_short.xlsx' , index_col = 0)\n",
    "\n",
    "# Substitui os valores NaN por zeros no DataFrame principal\n",
    "df_taxas_short.fillna(0, inplace=True)\n",
    "\n",
    "# Cria o DataFrame para as taxas short do SMAL11 e substitui NaN por 0\n",
    "df_taxa_short_smal = df_taxas_short[['SMAL11']].copy()\n",
    "df_taxa_short_smal.fillna(0, inplace=True)\n",
    "\n",
    "# Cria o DataFrame para as taxas short do IBOV e substitui NaN por 0\n",
    "df_taxa_short_ibov = df_taxas_short[['IBOV']].copy()\n",
    "df_taxa_short_ibov.fillna(0, inplace=True)\n",
    "\n",
    "# Remove SMAL11 e IBOV do DataFrame principal\n",
    "df_taxas_short = df_taxas_short.drop(columns=['SMAL11', 'IBOV'])\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"DataFrame taxas short do SMAL11 (df_taxa_short_smal):\")\n",
    "print(df_taxa_short_smal)\n",
    "print(\"\\nDataFrame taxas short do IBOV (df_taxa_short_ibov):\")\n",
    "print(df_taxa_short_ibov)\n",
    "print(\"\\nDataFrame com taxas short dos papéis (df_taxas_short):\")\n",
    "print(df_taxas_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7dfee4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TGMA3  ARML3  VAMO3     ALPA4     AZZA3  ASAI3  CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.051681    0.0    0.0 -0.029185 -0.033166      0    0.0    0.0   \n",
      "2019-09-03  0.051681    0.0    0.0 -0.029185 -0.033166      0    0.0    0.0   \n",
      "2019-09-04  0.051681    0.0    0.0 -0.029185 -0.033166      0    0.0    0.0   \n",
      "2019-09-05  0.051681    0.0    0.0 -0.029185 -0.033166      0    0.0    0.0   \n",
      "2019-09-06  0.051681    0.0    0.0 -0.029185 -0.033166      0    0.0    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    TAEE11    ALUP11  AZUL4     UNIP6  ORVR3  \\\n",
      "Data                      ...                                               \n",
      "2019-09-02      0    0.0  ...  0.045216  0.057994      0 -0.041053    0.0   \n",
      "2019-09-03      0    0.0  ...  0.045216  0.057994      0 -0.041053    0.0   \n",
      "2019-09-04      0    0.0  ...  0.045216  0.057994      0 -0.041053    0.0   \n",
      "2019-09-05      0    0.0  ...  0.045216  0.057994      0 -0.041053    0.0   \n",
      "2019-09-06      0    0.0  ...  0.045216  0.057994      0 -0.041053    0.0   \n",
      "\n",
      "            AMBP3  CVCB3  TASA4  GOLL4  EMBR3  \n",
      "Data                                           \n",
      "2019-09-02      0      0    0.0      0    0.0  \n",
      "2019-09-03      0      0    0.0      0    0.0  \n",
      "2019-09-04      0      0    0.0      0    0.0  \n",
      "2019-09-05      0      0    0.0      0    0.0  \n",
      "2019-09-06      0      0    0.0      0    0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n",
      "            peso_short_ibov\n",
      "Data                       \n",
      "2019-09-02                0\n",
      "2019-09-03                0\n",
      "2019-09-04                0\n",
      "2019-09-05                0\n",
      "2019-09-06                0\n",
      "            peso_short_smal\n",
      "Data                       \n",
      "2019-09-02                0\n",
      "2019-09-03                0\n",
      "2019-09-04                0\n",
      "2019-09-05                0\n",
      "2019-09-06                0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar dados de posicoes_net_otimizadas.xlsx com Data como índice\n",
    "df_posicoes_net = pd.read_excel(\n",
    "    'posicoes_net_otimizadas.xlsx',\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")\n",
    "df_posicoes_net.index.name = 'Data'\n",
    "\n",
    "# Carregar dados de posicoes_ibov_otimizadas.xlsx com Data como índice\n",
    "df_peso_short_ibov = pd.read_excel(\n",
    "    'posicoes_ibov_otimizadas.xlsx',\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")\n",
    "df_peso_short_ibov.index.name = 'Data'\n",
    "# Renomear coluna para corresponder ao formato esperado\n",
    "df_peso_short_ibov.rename(columns={'IBOV': 'peso_short_ibov'}, inplace=True)\n",
    "\n",
    "# Carregar dados de posicoes_smal_otimizadas.xlsx com Data como índice\n",
    "df_peso_short_smal = pd.read_excel(\n",
    "    'posicoes_smal_otimizadas.xlsx',\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")\n",
    "df_peso_short_smal.index.name = 'Data'\n",
    "# Renomear coluna para corresponder ao formato esperado\n",
    "df_peso_short_smal.rename(columns={'SMAL11': 'peso_short_smal'}, inplace=True)\n",
    "\n",
    "# Verificar os dataframes\n",
    "print(df_posicoes_net.head())\n",
    "print(df_peso_short_ibov.head())\n",
    "print(df_peso_short_smal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "43c8c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calcular_dataframes_interdependentes(df_perf, df_perf_ibov, df_perf_smal, df_perf_cdi, \n",
    "                                         df_posicoes_net, df_peso_short_ibov, df_peso_short_smal,\n",
    "                                         df_taxa_short_smal, df_taxa_short_ibov, df_taxas_short,\n",
    "                                         custo_rebalanceamento, custo_ajuste):\n",
    "    \"\"\"\n",
    "    Calcula os DataFrames interdependentes conforme as fórmulas definidas.\n",
    "    \"\"\"\n",
    "    # Obter as datas únicas de todos os DataFrames\n",
    "    datas = df_perf.index\n",
    "    \n",
    "    # Inicializar os DataFrames de resultado com NaN e mesmas dimensões dos DataFrames de entrada\n",
    "    # DataFrames que serão calculados para cada data\n",
    "    df_cota = pd.DataFrame(index=datas, columns=['cota'])\n",
    "    df_aloc = pd.DataFrame(index=datas, columns=df_posicoes_net.columns)\n",
    "    df_aloc_ibov = pd.DataFrame(index=datas, columns=['IBOV'])\n",
    "    df_aloc_smal = pd.DataFrame(index=datas, columns=['SMAL11'])\n",
    "    df_aloc_cdi = pd.DataFrame(index=datas, columns=['CDI'])\n",
    "    df_pel_papeis = pd.DataFrame(index=datas, columns=df_perf.columns)\n",
    "    df_pel_ibov = pd.DataFrame(index=datas, columns=['IBOV'])\n",
    "    df_pel_smal = pd.DataFrame(index=datas, columns=['SMAL11'])\n",
    "    df_pel_cdi = pd.DataFrame(index=datas, columns=['CDI'])\n",
    "    df_soma_pel_papeis = pd.DataFrame(index=datas, columns=['soma'])\n",
    "    df_soma_pel_hib_100 = pd.DataFrame(index=datas, columns=['soma'])\n",
    "    df_rebalanceamento_papeis = pd.DataFrame(index=datas, columns=df_perf.columns)\n",
    "    df_rebalanceamento_ibov = pd.DataFrame(index=datas, columns=['IBOV'])\n",
    "    df_rebalanceamento_smal = pd.DataFrame(index=datas, columns=['SMAL11'])\n",
    "    df_rebalanceamento = pd.DataFrame(index=datas, columns=['rebalanceamento'])\n",
    "    df_montagem_papeis = pd.DataFrame(index=datas, columns=df_perf.columns)\n",
    "    df_montagem_ibov = pd.DataFrame(index=datas, columns=['IBOV'])\n",
    "    df_montagem_smal = pd.DataFrame(index=datas, columns=['SMAL11'])\n",
    "    df_montagem = pd.DataFrame(index=datas, columns=['montagem'])\n",
    "    df_custos_short_papeis = pd.DataFrame(index=datas, columns=df_perf.columns)\n",
    "    df_custos_short_ibov = pd.DataFrame(index=datas, columns=['IBOV'])\n",
    "    df_custos_short_smal = pd.DataFrame(index=datas, columns=['SMAL11'])\n",
    "    df_custos_short = pd.DataFrame(index=datas, columns=['custos_short'])\n",
    "    df_custos = pd.DataFrame(index=datas, columns=['custos'])\n",
    "    \n",
    "    # Inicialização para o primeiro dia (índice 0)\n",
    "    primeira_data = datas[0]\n",
    "    \n",
    "    # Inicializar df_cota com 100 para o primeiro dia\n",
    "    df_cota.loc[primeira_data, 'cota'] = 100.0\n",
    "    \n",
    "    # Calcular alocações iniciais\n",
    "    df_aloc.loc[primeira_data] = df_cota.loc[primeira_data, 'cota'] * df_posicoes_net.loc[primeira_data]\n",
    "    df_aloc_ibov.loc[primeira_data, 'IBOV'] = df_cota.loc[primeira_data, 'cota'] * df_peso_short_ibov.loc[primeira_data, 'peso_short_ibov']\n",
    "    df_aloc_smal.loc[primeira_data, 'SMAL11'] = df_cota.loc[primeira_data, 'cota'] * df_peso_short_smal.loc[primeira_data, 'peso_short_smal']\n",
    "    df_aloc_cdi.loc[primeira_data, 'CDI'] = df_cota.loc[primeira_data, 'cota']\n",
    "    \n",
    "    # Para o primeiro dia, P&L é zero\n",
    "    df_pel_papeis.loc[primeira_data] = 0\n",
    "    df_pel_ibov.loc[primeira_data, 'IBOV'] = 0\n",
    "    df_pel_smal.loc[primeira_data, 'SMAL11'] = 0\n",
    "    df_pel_cdi.loc[primeira_data, 'CDI'] = 0\n",
    "    df_soma_pel_papeis.loc[primeira_data, 'soma'] = 0\n",
    "    df_soma_pel_hib_100.loc[primeira_data, 'soma'] = 0\n",
    "    \n",
    "    # Para o primeiro dia, rebalanceamento e montagem são zero\n",
    "    df_rebalanceamento_papeis.loc[primeira_data] = 0\n",
    "    df_rebalanceamento_ibov.loc[primeira_data, 'IBOV'] = 0\n",
    "    df_rebalanceamento_smal.loc[primeira_data, 'SMAL11'] = 0\n",
    "    df_rebalanceamento.loc[primeira_data, 'rebalanceamento'] = 0\n",
    "    df_montagem_papeis.loc[primeira_data] = 0\n",
    "    df_montagem_ibov.loc[primeira_data, 'IBOV'] = 0\n",
    "    df_montagem_smal.loc[primeira_data, 'SMAL11'] = 0\n",
    "    df_montagem.loc[primeira_data, 'montagem'] = 0\n",
    "    \n",
    "    # Custos de short para o primeiro dia\n",
    "    df_custos_short_papeis.loc[primeira_data] = np.where(\n",
    "        df_aloc.loc[primeira_data] < 0,\n",
    "        df_aloc.loc[primeira_data] * df_taxas_short.loc[primeira_data] / 252,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df_custos_short_ibov.loc[primeira_data, 'IBOV'] = (\n",
    "        df_aloc_ibov.loc[primeira_data, 'IBOV'] * df_taxa_short_ibov.loc[primeira_data, 'IBOV'] / 252\n",
    "        if df_aloc_ibov.loc[primeira_data, 'IBOV'] < 0\n",
    "        else 0\n",
    "    )\n",
    "    \n",
    "    df_custos_short_smal.loc[primeira_data, 'SMAL11'] = (\n",
    "        df_aloc_smal.loc[primeira_data, 'SMAL11'] * df_taxa_short_smal.loc[primeira_data, 'SMAL11'] / 252\n",
    "        if df_aloc_smal.loc[primeira_data, 'SMAL11'] < 0\n",
    "        else 0\n",
    "    )\n",
    "    \n",
    "    # Soma dos custos de short\n",
    "    df_custos_short.loc[primeira_data, 'custos_short'] = (\n",
    "        df_custos_short_papeis.loc[primeira_data].sum() +\n",
    "        df_custos_short_ibov.loc[primeira_data, 'IBOV'] +\n",
    "        df_custos_short_smal.loc[primeira_data, 'SMAL11']\n",
    "    )\n",
    "    \n",
    "    # Custos totais para o primeiro dia\n",
    "    df_custos.loc[primeira_data, 'custos'] = df_custos_short.loc[primeira_data, 'custos_short']\n",
    "    \n",
    "    # Loop para calcular os valores para os dias subsequentes\n",
    "    for i in range(1, len(datas)):\n",
    "        data_atual = datas[i]\n",
    "        data_anterior = datas[i-1]\n",
    "        \n",
    "        # Calcular P&L dos papéis, índices e CDI para o dia atual\n",
    "        df_pel_papeis.loc[data_atual] = df_aloc.loc[data_anterior] * df_perf.loc[data_atual]\n",
    "        df_pel_papeis.loc[data_atual].fillna(0, inplace=True)\n",
    "        \n",
    "        df_pel_ibov.loc[data_atual, 'IBOV'] = df_aloc_ibov.loc[data_anterior, 'IBOV'] * df_perf_ibov.loc[data_atual, 'IBOV']\n",
    "        df_pel_smal.loc[data_atual, 'SMAL11'] = df_aloc_smal.loc[data_anterior, 'SMAL11'] * df_perf_smal.loc[data_atual, 'SMAL11']\n",
    "        df_pel_cdi.loc[data_atual, 'CDI'] = df_aloc_cdi.loc[data_anterior, 'CDI'] * (df_perf_cdi.loc[data_atual, 'CDI'] - 1)\n",
    "        \n",
    "        # Soma do P&L dos papéis\n",
    "        df_soma_pel_papeis.loc[data_atual, 'soma'] = df_pel_papeis.loc[data_atual].sum()\n",
    "        \n",
    "        # Soma do P&L híbrido\n",
    "        df_soma_pel_hib_100.loc[data_atual, 'soma'] = (\n",
    "            df_soma_pel_papeis.loc[data_atual, 'soma'] +\n",
    "            df_pel_ibov.loc[data_atual, 'IBOV'] +\n",
    "            df_pel_smal.loc[data_atual, 'SMAL11'] +\n",
    "            df_pel_cdi.loc[data_atual, 'CDI']\n",
    "        )\n",
    "        \n",
    "        # Calcular df_cota para o dia atual\n",
    "        # Para isso, precisamos primeiro calcular os custos\n",
    "        \n",
    "        # Calcular alocações antes dos ajustes\n",
    "        temp_aloc = df_aloc.loc[data_anterior] + df_pel_papeis.loc[data_atual]\n",
    "        temp_aloc_ibov = df_aloc_ibov.loc[data_anterior, 'IBOV'] + df_pel_ibov.loc[data_atual, 'IBOV']\n",
    "        temp_aloc_smal = df_aloc_smal.loc[data_anterior, 'SMAL11'] + df_pel_smal.loc[data_atual, 'SMAL11']\n",
    "        \n",
    "        # Calcular a nova cota sem os custos primeiro\n",
    "        df_cota.loc[data_atual, 'cota'] = df_cota.loc[data_anterior, 'cota'] + df_soma_pel_hib_100.loc[data_atual, 'soma']\n",
    "        \n",
    "        # Calcular as novas alocações\n",
    "        df_aloc.loc[data_atual] = df_cota.loc[data_atual, 'cota'] * df_posicoes_net.loc[data_atual]\n",
    "        df_aloc_ibov.loc[data_atual, 'IBOV'] = df_cota.loc[data_atual, 'cota'] * df_peso_short_ibov.loc[data_atual, 'peso_short_ibov']\n",
    "        df_aloc_smal.loc[data_atual, 'SMAL11'] = df_cota.loc[data_atual, 'cota'] * df_peso_short_smal.loc[data_atual, 'peso_short_smal']\n",
    "        df_aloc_cdi.loc[data_atual, 'CDI'] = df_cota.loc[data_atual, 'cota']\n",
    "        \n",
    "        # Calcular rebalanceamento\n",
    "        df_rebalanceamento_papeis.loc[data_atual] = np.where(\n",
    "            (temp_aloc != 0) & (df_aloc.loc[data_atual] != 0),\n",
    "            np.abs(df_aloc.loc[data_atual] - temp_aloc),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        df_rebalanceamento_ibov.loc[data_atual, 'IBOV'] = (\n",
    "            np.abs(df_aloc_ibov.loc[data_atual, 'IBOV'] - temp_aloc_ibov)\n",
    "            if temp_aloc_ibov != 0 and df_aloc_ibov.loc[data_atual, 'IBOV'] != 0\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        df_rebalanceamento_smal.loc[data_atual, 'SMAL11'] = (\n",
    "            np.abs(df_aloc_smal.loc[data_atual, 'SMAL11'] - temp_aloc_smal)\n",
    "            if temp_aloc_smal != 0 and df_aloc_smal.loc[data_atual, 'SMAL11'] != 0\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        df_rebalanceamento.loc[data_atual, 'rebalanceamento'] = (\n",
    "            df_rebalanceamento_papeis.loc[data_atual].sum() +\n",
    "            df_rebalanceamento_ibov.loc[data_atual, 'IBOV'] +\n",
    "            df_rebalanceamento_smal.loc[data_atual, 'SMAL11']\n",
    "        )\n",
    "        \n",
    "        # Calcular montagem\n",
    "        df_montagem_papeis.loc[data_atual] = np.where(\n",
    "            (temp_aloc == 0) | (df_aloc.loc[data_atual] == 0),\n",
    "            np.abs(df_aloc.loc[data_atual] - temp_aloc),\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        df_montagem_ibov.loc[data_atual, 'IBOV'] = (\n",
    "            np.abs(df_aloc_ibov.loc[data_atual, 'IBOV'] - temp_aloc_ibov)\n",
    "            if temp_aloc_ibov == 0 or df_aloc_ibov.loc[data_atual, 'IBOV'] == 0\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        df_montagem_smal.loc[data_atual, 'SMAL11'] = (\n",
    "            np.abs(df_aloc_smal.loc[data_atual, 'SMAL11'] - temp_aloc_smal)\n",
    "            if temp_aloc_smal == 0 or df_aloc_smal.loc[data_atual, 'SMAL11'] == 0\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        df_montagem.loc[data_atual, 'montagem'] = (\n",
    "            df_montagem_papeis.loc[data_atual].sum() +\n",
    "            df_montagem_ibov.loc[data_atual, 'IBOV'] +\n",
    "            df_montagem_smal.loc[data_atual, 'SMAL11']\n",
    "        )\n",
    "        \n",
    "        # Calcular custos de short\n",
    "        df_custos_short_papeis.loc[data_atual] = np.where(\n",
    "            df_aloc.loc[data_atual] < 0,\n",
    "            df_aloc.loc[data_atual] * df_taxas_short.loc[data_atual] / 252,\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        df_custos_short_ibov.loc[data_atual, 'IBOV'] = (\n",
    "            df_aloc_ibov.loc[data_atual, 'IBOV'] * df_taxa_short_ibov.loc[data_atual, 'IBOV'] / 252\n",
    "            if df_aloc_ibov.loc[data_atual, 'IBOV'] < 0\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        df_custos_short_smal.loc[data_atual, 'SMAL11'] = (\n",
    "            df_aloc_smal.loc[data_atual, 'SMAL11'] * df_taxa_short_smal.loc[data_atual, 'SMAL11'] / 252\n",
    "            if df_aloc_smal.loc[data_atual, 'SMAL11'] < 0\n",
    "            else 0\n",
    "        )\n",
    "        \n",
    "        # Soma dos custos de short\n",
    "        df_custos_short.loc[data_atual, 'custos_short'] = (\n",
    "            df_custos_short_papeis.loc[data_atual].sum() +\n",
    "            df_custos_short_ibov.loc[data_atual, 'IBOV'] +\n",
    "            df_custos_short_smal.loc[data_atual, 'SMAL11']\n",
    "        )\n",
    "        \n",
    "        # Custos totais\n",
    "        df_custos.loc[data_atual, 'custos'] = (\n",
    "            -df_rebalanceamento.loc[data_atual, 'rebalanceamento'] * custo_rebalanceamento -\n",
    "            df_montagem.loc[data_atual, 'montagem'] * custo_ajuste +\n",
    "            df_custos_short.loc[data_atual, 'custos_short']\n",
    "        )\n",
    "        \n",
    "        # Atualizar df_cota com os custos\n",
    "        df_cota.loc[data_atual, 'cota'] = df_cota.loc[data_atual, 'cota'] + df_custos.loc[data_atual, 'custos']\n",
    "        \n",
    "        # Recalcular alocações com a cota atualizada\n",
    "        df_aloc.loc[data_atual] = df_cota.loc[data_atual, 'cota'] * df_posicoes_net.loc[data_atual]\n",
    "        df_aloc_ibov.loc[data_atual, 'IBOV'] = df_cota.loc[data_atual, 'cota'] * df_peso_short_ibov.loc[data_atual, 'peso_short_ibov']\n",
    "        df_aloc_smal.loc[data_atual, 'SMAL11'] = df_cota.loc[data_atual, 'cota'] * df_peso_short_smal.loc[data_atual, 'peso_short_smal']\n",
    "        df_aloc_cdi.loc[data_atual, 'CDI'] = df_cota.loc[data_atual, 'cota']\n",
    "    \n",
    "    # Substituir NaN por 0 em todos os dataframes\n",
    "    dataframes = [\n",
    "        df_cota, df_aloc, df_aloc_ibov, df_aloc_smal, df_aloc_cdi, df_pel_papeis, df_pel_ibov, df_pel_smal,\n",
    "        df_pel_cdi, df_soma_pel_papeis, df_soma_pel_hib_100, df_rebalanceamento_papeis, df_rebalanceamento_ibov,\n",
    "        df_rebalanceamento_smal, df_rebalanceamento, df_montagem_papeis, df_montagem_ibov, df_montagem_smal,\n",
    "        df_montagem, df_custos_short_papeis, df_custos_short_ibov, df_custos_short_smal, df_custos_short, df_custos\n",
    "    ]\n",
    "    \n",
    "    for df in dataframes:\n",
    "        df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Retornar todos os dataframes calculados\n",
    "    return {\n",
    "        'df_cota': df_cota,\n",
    "        'df_aloc': df_aloc,\n",
    "        'df_aloc_ibov': df_aloc_ibov,\n",
    "        'df_aloc_smal': df_aloc_smal,\n",
    "        'df_aloc_cdi': df_aloc_cdi,\n",
    "        'df_pel_papeis': df_pel_papeis,\n",
    "        'df_pel_ibov': df_pel_ibov,\n",
    "        'df_pel_smal': df_pel_smal,\n",
    "        'df_pel_cdi': df_pel_cdi,\n",
    "        'df_soma_pel_papeis': df_soma_pel_papeis,\n",
    "        'df_soma_pel_hib_100': df_soma_pel_hib_100,\n",
    "        'df_rebalanceamento_papeis': df_rebalanceamento_papeis,\n",
    "        'df_rebalanceamento_ibov': df_rebalanceamento_ibov,\n",
    "        'df_rebalanceamento_smal': df_rebalanceamento_smal,\n",
    "        'df_rebalanceamento': df_rebalanceamento,\n",
    "        'df_montagem_papeis': df_montagem_papeis,\n",
    "        'df_montagem_ibov': df_montagem_ibov,\n",
    "        'df_montagem_smal': df_montagem_smal,\n",
    "        'df_montagem': df_montagem,\n",
    "        'df_custos_short_papeis': df_custos_short_papeis,\n",
    "        'df_custos_short_ibov': df_custos_short_ibov,\n",
    "        'df_custos_short_smal': df_custos_short_smal,\n",
    "        'df_custos_short': df_custos_short,\n",
    "        'df_custos': df_custos\n",
    "    }\n",
    "\n",
    "# Exemplo de uso:\n",
    "# Defina os valores para custo_rebalanceamento e custo_ajuste\n",
    "# custo_rebalanceamento = 0.0005  # 0.05%\n",
    "# custo_ajuste = 0.0005  # 0.05%\n",
    "\n",
    "# Chame a função para calcular todos os dataframes\n",
    "# dataframes_calculados = calcular_dataframes_interdependentes(\n",
    "#     df_perf, df_perf_ibov, df_perf_smal, df_perf_cdi, \n",
    "#     df_posicoes_net, df_peso_short_ibov, df_peso_short_smal,\n",
    "#     df_taxa_short_smal, df_taxa_short_ibov, df_taxas_short,\n",
    "#     custo_rebalanceamento, custo_ajuste\n",
    "# )\n",
    "\n",
    "# Acesse os dataframes calculados\n",
    "# df_cota = dataframes_calculados['df_cota']\n",
    "# df_aloc = dataframes_calculados['df_aloc']\n",
    "# ... e assim por diante\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9b10a41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelMachado\\AppData\\Local\\Temp\\ipykernel_20188\\2902403571.py:107: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes_calculados = calcular_dataframes_interdependentes(\n",
    "     df_perf, df_perf_ibov, df_perf_smal, df_perf_cdi, \n",
    "     df_posicoes_net, df_peso_short_ibov, df_peso_short_smal,\n",
    "     df_taxa_short_smal, df_taxa_short_ibov, df_taxas_short,\n",
    "     custo_rebalanceamento, custo_ajuste\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6c39a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  cota\n",
      "Data                  \n",
      "2019-09-02       100.0\n",
      "2019-09-03  100.405951\n",
      "2019-09-04   99.384125\n",
      "2019-09-05   99.395634\n",
      "2019-09-06    100.2418\n",
      "...                ...\n",
      "2025-03-25  308.145691\n",
      "2025-03-26  309.180085\n",
      "2025-03-27  306.676336\n",
      "2025-03-28  303.966212\n",
      "2025-03-31   302.61592\n",
      "\n",
      "[1456 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_cota = dataframes_calculados['df_cota']\n",
    "print(df_cota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8b61caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            retorno_diario\n",
      "Data                      \n",
      "2019-09-02        0.000000\n",
      "2019-09-03        0.004060\n",
      "2019-09-04       -0.010177\n",
      "2019-09-05        0.000116\n",
      "2019-09-06        0.008513\n",
      "...                    ...\n",
      "2025-03-25        0.003400\n",
      "2025-03-26        0.003357\n",
      "2025-03-27       -0.008098\n",
      "2025-03-28       -0.008837\n",
      "2025-03-31       -0.004442\n",
      "\n",
      "[1456 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Garante que 'cota' é float\n",
    "df_cota['cota'] = pd.to_numeric(df_cota['cota'], errors='raise')\n",
    "\n",
    "# Agora pct_change() -> float, e fillna já não emite warning\n",
    "s_ret = df_cota['cota'].pct_change().fillna(0)\n",
    "df_retorno_diario = s_ret.to_frame('retorno_diario')\n",
    "\n",
    "print(df_retorno_diario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "566123ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  cota\n",
      "Data                  \n",
      "2020-09-02  100.000000\n",
      "2020-09-03  100.246476\n",
      "2020-09-04  100.079901\n",
      "2020-09-07  100.102946\n",
      "2020-09-08   99.842745\n",
      "                  cota\n",
      "Data                  \n",
      "2025-03-25  314.472671\n",
      "2025-03-26  315.528304\n",
      "2025-03-27  312.973147\n",
      "2025-03-28  310.207378\n",
      "2025-03-31  308.829361\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Função para criar dataframe de cotas personalizadas\n",
    "def criar_cotas_personalizadas(df_cota, df_retorno_diario, data_primeira_cota):\n",
    "    \"\"\"\n",
    "    Cria um dataframe de cotas personalizadas a partir de uma data específica.\n",
    "    \n",
    "    Parâmetros:\n",
    "    df_cota (DataFrame): DataFrame contendo as cotas originais\n",
    "    df_retorno_diario (DataFrame): DataFrame contendo os retornos diários\n",
    "    data_primeira_cota (str): Data a partir da qual a primeira cota será 100 (formato 'YYYY-MM-DD')\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame: Novo dataframe com as cotas personalizadas\n",
    "    \"\"\"\n",
    "    # Convertendo a data para o formato datetime se for string\n",
    "    if isinstance(data_primeira_cota, str):\n",
    "        data_primeira_cota = pd.to_datetime(data_primeira_cota)\n",
    "    \n",
    "    # Verificando se a data está presente nos dataframes\n",
    "    if data_primeira_cota not in df_cota.index:\n",
    "        raise ValueError(f\"A data {data_primeira_cota} não está presente no dataframe de cotas.\")\n",
    "    \n",
    "    # Filtrando os dataframes a partir da data escolhida\n",
    "    df_cota_filtrado = df_cota.loc[data_primeira_cota:]\n",
    "    df_retorno_filtrado = df_retorno_diario.loc[data_primeira_cota:]\n",
    "    \n",
    "    # Criando novo dataframe para as cotas personalizadas\n",
    "    df_cotas_personalizadas = pd.DataFrame(index=df_cota_filtrado.index)\n",
    "    \n",
    "    # Definindo a primeira cota como 100\n",
    "    df_cotas_personalizadas.loc[data_primeira_cota, 'cota'] = 100.0\n",
    "    \n",
    "    # Calculando as cotas subsequentes com base nos retornos diários\n",
    "    for i in range(1, len(df_cotas_personalizadas)):\n",
    "        data_atual = df_cotas_personalizadas.index[i]\n",
    "        data_anterior = df_cotas_personalizadas.index[i-1]\n",
    "        retorno = df_retorno_filtrado.loc[data_atual, 'retorno_diario']\n",
    "        cota_anterior = df_cotas_personalizadas.loc[data_anterior, 'cota']\n",
    "        \n",
    "        # Calculando a nova cota: cota anterior * (1 + retorno diário)\n",
    "        df_cotas_personalizadas.loc[data_atual, 'cota'] = cota_anterior * (1 + retorno)\n",
    "    \n",
    "    return df_cotas_personalizadas\n",
    "\n",
    "# Exemplo de uso:\n",
    "# Supondo que df_cota e df_retorno_diario são seus dataframes originais\n",
    "# Data escolhida pelo usuário\n",
    "df_cotas_personalizadas = criar_cotas_personalizadas(df_cota, df_retorno_diario, data_escolhida)\n",
    "print(df_cotas_personalizadas.head())\n",
    "print(df_cotas_personalizadas.tail())\n",
    "\n",
    "df_cota = df_cotas_personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a0f0398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Drawdown\n",
      "Data                \n",
      "2020-09-02  0.000000\n",
      "2020-09-03  0.000000\n",
      "2020-09-04 -0.001662\n",
      "2020-09-07 -0.001432\n",
      "2020-09-08 -0.004027\n",
      "...              ...\n",
      "2025-03-25 -0.003211\n",
      "2025-03-26  0.000000\n",
      "2025-03-27 -0.008098\n",
      "2025-03-28 -0.016864\n",
      "2025-03-31 -0.021231\n",
      "\n",
      "[1194 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1) Cria um df temporário contendo só a coluna de drawdown\n",
    "df_temp = df_cota.copy()\n",
    "df_temp['Drawdown'] = df_temp['cota'].div(df_temp['cota'].cummax()) - 1\n",
    "\n",
    "# 2) Seleciona apenas a coluna drawdown\n",
    "df_drawdown = df_temp[['Drawdown']]\n",
    "\n",
    "print(df_drawdown)\n",
    "# O primeiro dia: cummax == cota, logo drawdown == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0c360a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            retorno_acumulado_CDI\n",
      "Data                             \n",
      "2020-09-02               0.000000\n",
      "2020-09-03               0.000075\n",
      "2020-09-04               0.000149\n",
      "2020-09-07               0.000396\n",
      "2020-09-08               0.000470\n",
      "...                           ...\n",
      "2025-03-25               0.542288\n",
      "2025-03-26               0.543099\n",
      "2025-03-27               0.543909\n",
      "2025-03-28               0.544720\n",
      "2025-03-31               0.545532\n",
      "\n",
      "[1194 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converter para datetime se necessário\n",
    "from datetime import datetime\n",
    "if isinstance(data_escolhida, str):\n",
    "    data_escolhida = datetime.strptime(data_escolhida, '%Y-%m-%d')\n",
    "\n",
    "# Filtrar o dataframe para incluir apenas datas a partir da data escolhida\n",
    "df_cdi_acumulado = (\n",
    "    df_perf_cdi\n",
    "    .assign(retorno_acumulado_CDI = df_perf_cdi['CDI'].cumprod() - 1)\n",
    "    [['retorno_acumulado_CDI']]\n",
    ")\n",
    "\n",
    "# Filtrar o dataframe a partir da data escolhida\n",
    "df_cdi_acumulado = df_cdi_acumulado[df_cdi_acumulado.index >= data_escolhida]\n",
    "\n",
    "# Recalcular o retorno acumulado a partir do primeiro dia como base zero\n",
    "primeiro_valor = df_cdi_acumulado['retorno_acumulado_CDI'].iloc[0]\n",
    "df_cdi_acumulado['retorno_acumulado_CDI'] = (\n",
    "    (1 + df_cdi_acumulado['retorno_acumulado_CDI']) / (1 + primeiro_valor) - 1\n",
    ")\n",
    "\n",
    "print(df_cdi_acumulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9bbf3057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            retorno_ytd\n",
      "Data                   \n",
      "2020-09-02     0.000000\n",
      "2020-09-03     0.002465\n",
      "2020-09-04     0.000799\n",
      "2020-09-07     0.001029\n",
      "2020-09-08    -0.001573\n",
      "...                 ...\n",
      "2025-03-25     0.125991\n",
      "2025-03-26     0.129771\n",
      "2025-03-27     0.120622\n",
      "2025-03-28     0.110719\n",
      "2025-03-31     0.105785\n",
      "\n",
      "[1194 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def calcular_ytd_diario_reset_anual(df_cota, data_inicial=None):\n",
    "    \"\"\"\n",
    "    Calcula o retorno YTD diário, reiniciando a contagem a cada aniversário da data inicial.\n",
    "    \n",
    "    Args:\n",
    "        df_cota: DataFrame com as cotas diárias (índice como datas)\n",
    "        data_inicial: Data de início (se None, usa a primeira data do DataFrame)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com os retornos YTD diários ressetados a cada ano\n",
    "    \"\"\"\n",
    "    # Garantir que o índice é datetime\n",
    "    if not isinstance(df_cota.index, pd.DatetimeIndex):\n",
    "        df_cota.index = pd.to_datetime(df_cota.index)\n",
    "    \n",
    "    # Se data_inicial não for especificada, usar a primeira data do DataFrame\n",
    "    if data_inicial is None:\n",
    "        data_inicial = df_cota.index[0]\n",
    "    else:\n",
    "        data_inicial = pd.to_datetime(data_inicial)\n",
    "    \n",
    "    # Extrair dia e mês da data inicial (assegurar que são inteiros)\n",
    "    dia_ref = int(data_inicial.day)\n",
    "    mes_ref = int(data_inicial.month)\n",
    "    \n",
    "    # Criar uma função para determinar o ano da janela para cada data\n",
    "    def determinar_ano_janela(data):\n",
    "        if (data.month < mes_ref) or (data.month == mes_ref and data.day < dia_ref):\n",
    "            return int(data.year - data_inicial.year)\n",
    "        else:\n",
    "            return int(data.year - data_inicial.year + 1)\n",
    "    \n",
    "    # Criar um DataFrame de resultado\n",
    "    df_resultado = df_cota.copy()\n",
    "    df_resultado['ano_janela'] = df_resultado.index.map(determinar_ano_janela)\n",
    "    \n",
    "    # Função para encontrar a data de início de cada janela anual\n",
    "    def encontrar_data_inicio_janela(data, ano_janela):\n",
    "        # Garantir que ano_janela é int\n",
    "        ano_janela = int(ano_janela)\n",
    "        \n",
    "        # Para o primeiro ano (ano_janela = 1), a data de início é a data_inicial\n",
    "        if ano_janela == 1:\n",
    "            return data_inicial\n",
    "        \n",
    "        # Para anos subsequentes, é o aniversário da data inicial no ano correspondente\n",
    "        ano_calendario = int(data_inicial.year + ano_janela - 1)\n",
    "        \n",
    "        # Tentar criar a data diretamente\n",
    "        try:\n",
    "            data_inicio = datetime(ano_calendario, mes_ref, dia_ref)\n",
    "        except ValueError:  # Lidar com casos como 29 de fevereiro em anos não bissextos\n",
    "            # Neste caso, usar o último dia do mês\n",
    "            if mes_ref == 2 and dia_ref == 29:\n",
    "                data_inicio = datetime(ano_calendario, mes_ref, 28)\n",
    "            else:\n",
    "                # Para outros casos improváveis, usar o primeiro dia do mês seguinte\n",
    "                if mes_ref == 12:\n",
    "                    data_inicio = datetime(ano_calendario + 1, 1, 1)\n",
    "                else:\n",
    "                    data_inicio = datetime(ano_calendario, mes_ref + 1, 1)\n",
    "        \n",
    "        # Verificar se esta data está no DataFrame, caso contrário, encontrar a próxima data disponível\n",
    "        while data_inicio not in df_cota.index and data_inicio <= data:\n",
    "            data_inicio += timedelta(days=1)\n",
    "        \n",
    "        return data_inicio\n",
    "    \n",
    "    # Calcular o YTD para cada dia\n",
    "    ytd_values = []\n",
    "    data_inicio_values = []\n",
    "    \n",
    "    for date, row in df_resultado.iterrows():\n",
    "        ano_janela = row['ano_janela']\n",
    "        data_inicio_janela = encontrar_data_inicio_janela(date, ano_janela)\n",
    "        data_inicio_values.append(data_inicio_janela)\n",
    "        \n",
    "        # Encontrar a cota no início da janela atual\n",
    "        cota_inicio_janela = df_cota.loc[data_inicio_janela, 'cota']\n",
    "        \n",
    "        # Calcular o YTD para esta data\n",
    "        cota_atual = row['cota']\n",
    "        ytd = (cota_atual / cota_inicio_janela) - 1\n",
    "        \n",
    "        ytd_values.append(ytd)\n",
    "    \n",
    "    # Adicionar a coluna de YTD ao DataFrame de resultado\n",
    "    df_resultado['data_inicio_janela'] = data_inicio_values\n",
    "    df_resultado['ytd'] = ytd_values\n",
    "    \n",
    "    # Criar um dataframe final apenas com data e YTD\n",
    "    df_ytd_final = pd.DataFrame(index=df_resultado.index)\n",
    "    df_ytd_final['retorno_ytd'] = df_resultado['ytd']\n",
    "    \n",
    "    return df_ytd_final\n",
    "\n",
    "# Exemplo de uso:\n",
    "data_inicial = data_escolhida  # Sua data inicial (primeiro dia da amostra)\n",
    "df_ytd = calcular_ytd_diario_reset_anual(df_cota, data_inicial)\n",
    "\n",
    "print(df_ytd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c3b2e0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Período Data Início   Data Fim  Dias no Período  Retorno YTD  \\\n",
      "0   Ano 1  2020-09-02 2021-09-02              366     0.000000   \n",
      "1   Ano 2  2021-09-02 2022-09-02              366     0.000000   \n",
      "2   Ano 3  2022-09-02 2023-09-01              365     0.224642   \n",
      "3   Ano 4  2023-09-04 2024-09-02              365     0.000000   \n",
      "4   Ano 5  2024-09-02 2025-03-31              211     0.105785   \n",
      "\n",
      "   Retorno Período  Retorno Anualizado  CDI Período  CDI Anualizado  \n",
      "0         0.226628            0.225944     0.029562        0.029480  \n",
      "1         0.377460            0.376255     0.104052        0.103753  \n",
      "2         0.224642            0.224642     0.138537        0.138537  \n",
      "3         0.351989            0.351989     0.118030        0.118030  \n",
      "4         0.105785            0.189992     0.069413        0.123098  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def extrair_retornos_anuais(df_ytd, df_cota, df_perf_cdi, data_inicial):\n",
    "    \"\"\"\n",
    "    Extrai, para cada aniversário de data_inicial até o fim dos dados, os seguintes retornos anuais:\n",
    "      - Retorno YTD (fundo)\n",
    "      - Retorno do período (fundo)\n",
    "      - Retorno anualizado (fundo)\n",
    "      - CDI do período\n",
    "      - CDI anualizado\n",
    "\n",
    "    Args:\n",
    "        df_ytd: DataFrame com os retornos YTD diários do fundo (coluna 'retorno_ytd')\n",
    "        df_cota: DataFrame com as cotas diárias do fundo (coluna 'cota')\n",
    "        df_perf_cdi: DataFrame com os fatores diários do CDI (coluna 'CDI')\n",
    "        data_inicial: Data de início da amostra (string ou datetime)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame com uma linha por período anual, contendo todas as métricas acima.\n",
    "    \"\"\"\n",
    "    # Garante índices em datetime\n",
    "    for df in (df_ytd, df_cota, df_perf_cdi):\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    data_inicial = pd.to_datetime(data_inicial)\n",
    "    if data_inicial not in df_cota.index:\n",
    "        posteriores = df_cota.index[df_cota.index >= data_inicial]\n",
    "        if len(posteriores) > 0:\n",
    "            data_inicial = posteriores[0]\n",
    "            print(f\"Data inicial ajustada para: {data_inicial}\")\n",
    "        else:\n",
    "            raise ValueError(\"Data inicial fora do range do dataframe de cotas.\")\n",
    "\n",
    "    dia_ref, mes_ref = data_inicial.day, data_inicial.month\n",
    "    datas_aniv = []\n",
    "    ano = data_inicial.year\n",
    "    # gera aniversários até o fim dos dados\n",
    "    while True:\n",
    "        try:\n",
    "            aniv = datetime(ano, mes_ref, dia_ref)\n",
    "        except ValueError:\n",
    "            aniv = datetime(ano, mes_ref, 28)  # feb 29->28 ou fallback\n",
    "        if df_cota.index[0] <= aniv <= df_cota.index[-1]:\n",
    "            datas_aniv.append(aniv)\n",
    "        ano += 1\n",
    "        # checa se próximo ano ainda cabe\n",
    "        if datetime(ano, mes_ref, min(dia_ref,28)) > df_cota.index[-1]:\n",
    "            break\n",
    "    # inclui última data disponível se necessária\n",
    "    if datas_aniv and df_cota.index[-1] > datas_aniv[-1]:\n",
    "        datas_aniv.append(df_cota.index[-1])\n",
    "    if len(datas_aniv) < 2:\n",
    "        raise ValueError(\"Não há aniversários suficientes para cálculo de períodos anuais.\")\n",
    "\n",
    "    def prox_data(data, antes=True):\n",
    "        \"\"\"\n",
    "        Retorna a data disponível mais próxima a 'data' no df_cota.\n",
    "        Se 'antes' for True, prioriza datas <= data, senão >= data.\n",
    "        \"\"\"\n",
    "        if data in df_cota.index:\n",
    "            return data\n",
    "        if antes:\n",
    "            ant = df_cota.index[df_cota.index < data]\n",
    "            if len(ant) > 0:\n",
    "                return ant[-1]\n",
    "        pos = df_cota.index[df_cota.index > data]\n",
    "        if len(pos) > 0:\n",
    "            return pos[0]\n",
    "        return df_cota.index[0] if antes else df_cota.index[-1]\n",
    "\n",
    "    resultados = []\n",
    "    for i in range(len(datas_aniv)-1):\n",
    "        dt_i = prox_data(datas_aniv[i], antes=False)\n",
    "        dt_f = prox_data(datas_aniv[i+1], antes=True)\n",
    "        if dt_f <= dt_i:\n",
    "            continue\n",
    "        dias = (dt_f - dt_i).days + 1\n",
    "        # retornos fundo\n",
    "        ret_ytd = df_ytd.loc[dt_f, 'retorno_ytd']\n",
    "        cota_i = df_cota.loc[dt_i, 'cota']\n",
    "        cota_f = df_cota.loc[dt_f, 'cota']\n",
    "        ret_periodo = (cota_f / cota_i) - 1\n",
    "        ret_ann = (1 + ret_periodo)**(365 / dias) - 1\n",
    "        # retornos CDI\n",
    "        cdi_slice = df_perf_cdi.loc[dt_i:dt_f, 'CDI']\n",
    "        cdi_periodo = cdi_slice.prod() - 1\n",
    "        cdi_ann = (1 + cdi_periodo)**(365 / dias) - 1\n",
    "        resultados.append({\n",
    "            'Período': f\"Ano {i+1}\",\n",
    "            'Data Início': dt_i,\n",
    "            'Data Fim': dt_f,\n",
    "            'Dias no Período': dias,\n",
    "            'Retorno YTD': ret_ytd,\n",
    "            'Retorno Período': ret_periodo,\n",
    "            'Retorno Anualizado': ret_ann,\n",
    "            'CDI Período': cdi_periodo,\n",
    "            'CDI Anualizado': cdi_ann\n",
    "        })\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "# Exemplo de uso:\n",
    "df_retornos = extrair_retornos_anuais(df_ytd, df_cota, df_perf_cdi, data_escolhida)\n",
    "print(df_retornos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "03241a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatilidade_252</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>0.077819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>0.077593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02</th>\n",
       "      <td>0.075160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-03</th>\n",
       "      <td>0.072233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-04</th>\n",
       "      <td>0.073017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-25</th>\n",
       "      <td>0.073219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-26</th>\n",
       "      <td>0.073036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-27</th>\n",
       "      <td>0.077923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28</th>\n",
       "      <td>0.079641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31</th>\n",
       "      <td>0.079048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            volatilidade_252\n",
       "Data                        \n",
       "2019-09-30          0.077819\n",
       "2019-10-01          0.077593\n",
       "2019-10-02          0.075160\n",
       "2019-10-03          0.072233\n",
       "2019-10-04          0.073017\n",
       "...                      ...\n",
       "2025-03-25          0.073219\n",
       "2025-03-26          0.073036\n",
       "2025-03-27          0.077923\n",
       "2025-03-28          0.079641\n",
       "2025-03-31          0.079048\n",
       "\n",
       "[1436 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) garanta que o índice é datetime e está ordenado\n",
    "df_retorno_diario = df_retorno_diario.sort_index()\n",
    "df_retorno_diario.index = pd.to_datetime(df_retorno_diario.index)\n",
    "\n",
    "# 2) calcula o desvio-padrão móvel de 252 dias (ddof=1)\n",
    "vol_252 = df_retorno_diario['retorno_diario'] \\\n",
    "    .rolling(window=21, min_periods=21) \\\n",
    "    .std(ddof=1) \\\n",
    "    * np.sqrt(252)\n",
    "\n",
    "# 3) monta o novo DataFrame\n",
    "df_vol_252 = vol_252.to_frame(name='volatilidade_252')\n",
    "\n",
    "# opcional: remover as primeiras 251 linhas com NaN\n",
    "df_vol_252 = df_vol_252.dropna()\n",
    "\n",
    "display(df_vol_252)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f01a8ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            volatilidade_ytd\n",
      "Data                        \n",
      "2020-09-02          0.000000\n",
      "2020-09-03          0.000000\n",
      "2020-09-04          0.046319\n",
      "2020-09-07          0.032790\n",
      "2020-09-08          0.035535\n",
      "...                      ...\n",
      "2025-03-25          0.070423\n",
      "2025-03-26          0.070259\n",
      "2025-03-27          0.070987\n",
      "2025-03-28          0.071846\n",
      "2025-03-31          0.071920\n",
      "\n",
      "[1194 rows x 1 columns]\n",
      "  Período Data Início   Data Fim  Volatilidade YTD  Volatilidade Período  \\\n",
      "0   Ano 1  2020-09-02 2021-09-02          0.000000              0.099377   \n",
      "1   Ano 2  2021-09-02 2022-09-02          0.000000              0.106282   \n",
      "2   Ano 3  2022-09-02 2023-09-01          0.082484              0.082484   \n",
      "3   Ano 4  2023-09-04 2024-09-02          0.000000              0.073891   \n",
      "4   Ano 5  2024-09-02 2025-03-31          0.071920              0.071920   \n",
      "\n",
      "   Dias no Período  \n",
      "0              366  \n",
      "1              366  \n",
      "2              365  \n",
      "3              365  \n",
      "4              211  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def calcular_volatilidade_ytd_diario_reset_anual(df_cota, data_inicial=None, janela_anualizada=252):\n",
    "    \"\"\"\n",
    "    Calcula a volatilidade YTD diária, reiniciando a contagem a cada aniversário da data inicial.\n",
    "    \n",
    "    Args:\n",
    "        df_cota: DataFrame com as cotas diárias (índice como datas)\n",
    "        data_inicial: Data de início (se None, usa a primeira data do DataFrame)\n",
    "        janela_anualizada: Número de dias úteis em um ano para anualização (padrão: 252)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com as volatilidades YTD diárias ressetadas a cada ano\n",
    "    \"\"\"\n",
    "    # Garantir que o índice é datetime\n",
    "    if not isinstance(df_cota.index, pd.DatetimeIndex):\n",
    "        df_cota.index = pd.to_datetime(df_cota.index)\n",
    "    \n",
    "    # Se data_inicial não for especificada, usar a primeira data do DataFrame\n",
    "    if data_inicial is None:\n",
    "        data_inicial = df_cota.index[0]\n",
    "    else:\n",
    "        data_inicial = pd.to_datetime(data_inicial)\n",
    "    \n",
    "    # Extrair dia e mês da data inicial (assegurar que são inteiros)\n",
    "    dia_ref = int(data_inicial.day)\n",
    "    mes_ref = int(data_inicial.month)\n",
    "    \n",
    "    # Calcular retornos diários\n",
    "    df_resultado = df_cota.copy()\n",
    "    df_resultado['retorno_diario'] = df_resultado['cota'].pct_change()\n",
    "    \n",
    "    # Criar uma função para determinar o ano da janela para cada data\n",
    "    def determinar_ano_janela(data):\n",
    "        if (data.month < mes_ref) or (data.month == mes_ref and data.day < dia_ref):\n",
    "            return int(data.year - data_inicial.year)\n",
    "        else:\n",
    "            return int(data.year - data_inicial.year + 1)\n",
    "    \n",
    "    # Adicionar coluna de ano da janela\n",
    "    df_resultado['ano_janela'] = df_resultado.index.map(determinar_ano_janela)\n",
    "    \n",
    "    # Função para encontrar a data de início de cada janela anual\n",
    "    def encontrar_data_inicio_janela(data, ano_janela):\n",
    "        # Garantir que ano_janela é int\n",
    "        ano_janela = int(ano_janela)\n",
    "        \n",
    "        # Para o primeiro ano (ano_janela = 1), a data de início é a data_inicial\n",
    "        if ano_janela == 1:\n",
    "            return data_inicial\n",
    "        \n",
    "        # Para anos subsequentes, é o aniversário da data inicial no ano correspondente\n",
    "        ano_calendario = int(data_inicial.year + ano_janela - 1)\n",
    "        \n",
    "        # Tentar criar a data diretamente\n",
    "        try:\n",
    "            data_inicio = datetime(ano_calendario, mes_ref, dia_ref)\n",
    "        except ValueError:  # Lidar com casos como 29 de fevereiro em anos não bissextos\n",
    "            # Neste caso, usar o último dia do mês\n",
    "            if mes_ref == 2 and dia_ref == 29:\n",
    "                data_inicio = datetime(ano_calendario, mes_ref, 28)\n",
    "            else:\n",
    "                # Para outros casos improváveis, usar o primeiro dia do mês seguinte\n",
    "                if mes_ref == 12:\n",
    "                    data_inicio = datetime(ano_calendario + 1, 1, 1)\n",
    "                else:\n",
    "                    data_inicio = datetime(ano_calendario, mes_ref + 1, 1)\n",
    "        \n",
    "        # Verificar se esta data está no DataFrame, caso contrário, encontrar a próxima data disponível\n",
    "        while data_inicio not in df_cota.index and data_inicio <= data:\n",
    "            data_inicio += timedelta(days=1)\n",
    "        \n",
    "        return data_inicio\n",
    "    \n",
    "    # Calcular a volatilidade para cada dia\n",
    "    volatilidade_values = []\n",
    "    data_inicio_values = []\n",
    "    \n",
    "    for date, row in df_resultado.iterrows():\n",
    "        ano_janela = row['ano_janela']\n",
    "        data_inicio_janela = encontrar_data_inicio_janela(date, ano_janela)\n",
    "        data_inicio_values.append(data_inicio_janela)\n",
    "        \n",
    "        # Obter todos os retornos diários desde o início da janela até a data atual\n",
    "        mask = (df_resultado.index >= data_inicio_janela) & (df_resultado.index <= date)\n",
    "        retornos_periodo = df_resultado.loc[mask, 'retorno_diario'].dropna()\n",
    "        \n",
    "        # Calcular a volatilidade (desvio padrão dos retornos) anualizada\n",
    "        if len(retornos_periodo) > 1:\n",
    "            vol_diaria = np.std(retornos_periodo, ddof=1)\n",
    "            # Anualizar a volatilidade\n",
    "            vol_anualizada = vol_diaria * np.sqrt(janela_anualizada)\n",
    "            volatilidade_values.append(vol_anualizada)\n",
    "        else:\n",
    "            # Se não há dados suficientes, atribuir NaN\n",
    "            volatilidade_values.append(np.nan)\n",
    "    \n",
    "    # Adicionar as colunas calculadas ao DataFrame de resultado\n",
    "    df_resultado['data_inicio_janela'] = data_inicio_values\n",
    "    df_resultado['volatilidade_ytd'] = volatilidade_values\n",
    "    \n",
    "    # Criar um dataframe final apenas com data e volatilidade\n",
    "    df_vol_final = pd.DataFrame(index=df_resultado.index)\n",
    "    df_vol_final['volatilidade_ytd'] = df_resultado['volatilidade_ytd']\n",
    "    \n",
    "    # Substitui NaN por 0\n",
    "    df_vol_final = df_vol_final.fillna(0)\n",
    "    return df_vol_final\n",
    "\n",
    "def extrair_volatilidade_anual(df_vol, df_cota, data_inicial, janela_anualizada=252):\n",
    "    \"\"\"\n",
    "    Extrai as volatilidades do último dia de cada período anual\n",
    "    \n",
    "    Args:\n",
    "        df_vol: DataFrame com as volatilidades YTD diárias\n",
    "        df_cota: DataFrame com as cotas diárias\n",
    "        data_inicial: Data de início da amostra\n",
    "        janela_anualizada: Número de dias úteis em um ano para anualização (padrão: 252)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com as volatilidades do último dia de cada período anual\n",
    "    \"\"\"\n",
    "    # Garantir que os índices dos dataframes são datetime\n",
    "    if not isinstance(df_vol.index, pd.DatetimeIndex):\n",
    "        df_vol.index = pd.to_datetime(df_vol.index)\n",
    "    if not isinstance(df_cota.index, pd.DatetimeIndex):\n",
    "        df_cota.index = pd.to_datetime(df_cota.index)\n",
    "    \n",
    "    # Converter data_inicial para datetime\n",
    "    data_inicial = pd.to_datetime(data_inicial)\n",
    "    \n",
    "    # Verificar se a data_inicial está no dataframe, se não, encontrar a mais próxima\n",
    "    if data_inicial not in df_cota.index:\n",
    "        # Encontrar a primeira data disponível após a data inicial\n",
    "        datas_posteriores = df_cota.index[df_cota.index >= data_inicial]\n",
    "        if len(datas_posteriores) > 0:\n",
    "            data_inicial = datas_posteriores[0]\n",
    "            print(f\"Data inicial ajustada para a primeira data disponível: {data_inicial}\")\n",
    "        else:\n",
    "            raise ValueError(\"Data inicial não encontrada e não há datas posteriores disponíveis\")\n",
    "    \n",
    "    # Extrair dia e mês de referência para os aniversários\n",
    "    dia_ref = int(data_inicial.day)\n",
    "    mes_ref = int(data_inicial.month)\n",
    "    \n",
    "    # Calcular as datas de aniversário\n",
    "    datas_aniversario = []\n",
    "    ano_atual = data_inicial.year\n",
    "    while True:\n",
    "        # Calcular a próxima data de aniversário\n",
    "        try:\n",
    "            data_aniv = datetime(ano_atual, mes_ref, dia_ref)\n",
    "        except ValueError:  # Lidar com anos bissextos\n",
    "            if mes_ref == 2 and dia_ref == 29:\n",
    "                data_aniv = datetime(ano_atual, mes_ref, 28)\n",
    "            else:\n",
    "                # Outro caso especial\n",
    "                data_aniv = datetime(ano_atual, mes_ref, 1)\n",
    "        \n",
    "        # Só considerar datas dentro do range do dataframe\n",
    "        if data_aniv >= df_cota.index[0] and data_aniv <= df_cota.index[-1]:\n",
    "            datas_aniversario.append(data_aniv)\n",
    "        \n",
    "        # Adicionar mais um ano e verificar se ainda está no range\n",
    "        ano_atual += 1\n",
    "        proxima_data = datetime(ano_atual, mes_ref, min(dia_ref, 28))\n",
    "        if proxima_data > df_cota.index[-1]:\n",
    "            break\n",
    "    \n",
    "    # Adicionar a última data do dataframe como fim do último período\n",
    "    if len(datas_aniversario) > 0 and df_cota.index[-1] > datas_aniversario[-1]:\n",
    "        datas_aniversario.append(df_cota.index[-1])\n",
    "    \n",
    "    # Se não houver pelo menos um aniversário e a data final, não temos períodos para calcular\n",
    "    if len(datas_aniversario) < 2:\n",
    "        raise ValueError(\"Não há períodos anuais completos nos dados fornecidos\")\n",
    "    \n",
    "    # Função para encontrar a data disponível mais próxima\n",
    "    def encontrar_data_disponivel(data_alvo, buscar_antes=True):\n",
    "        \"\"\"\n",
    "        Encontra a data disponível mais próxima no dataframe\n",
    "        \n",
    "        Args:\n",
    "            data_alvo: Data desejada\n",
    "            buscar_antes: Se True, busca datas anteriores quando a data alvo não está disponível\n",
    "            \n",
    "        Returns:\n",
    "            Data disponível mais próxima\n",
    "        \"\"\"\n",
    "        # Se a data alvo estiver disponível, retorná-la\n",
    "        if data_alvo in df_cota.index:\n",
    "            return data_alvo\n",
    "        \n",
    "        # Caso contrário, buscar a data mais próxima\n",
    "        if buscar_antes:\n",
    "            # Buscar datas anteriores\n",
    "            datas_anteriores = df_cota.index[df_cota.index < data_alvo]\n",
    "            if len(datas_anteriores) > 0:\n",
    "                return datas_anteriores[-1]  # Última data antes da data alvo\n",
    "        \n",
    "        # Buscar datas posteriores\n",
    "        datas_posteriores = df_cota.index[df_cota.index > data_alvo]\n",
    "        if len(datas_posteriores) > 0:\n",
    "            return datas_posteriores[0]  # Primeira data após a data alvo\n",
    "        \n",
    "        # Se não encontrar nenhuma data, usar a primeira ou última data disponível\n",
    "        if buscar_antes:\n",
    "            return df_cota.index[0]  # Primeira data do dataframe\n",
    "        else:\n",
    "            return df_cota.index[-1]  # Última data do dataframe\n",
    "    \n",
    "    # Calcular retornos diários para volatilidade do período\n",
    "    df_retornos = df_cota.copy()\n",
    "    df_retornos['retorno_diario'] = df_retornos['cota'].pct_change()\n",
    "    \n",
    "    # Lista para armazenar os resultados\n",
    "    resultados = []\n",
    "    \n",
    "    # Calcular as volatilidades para cada período anual\n",
    "    for i in range(len(datas_aniversario) - 1):\n",
    "        # Encontrar as datas de início e fim reais (disponíveis nos dados)\n",
    "        data_inicio = encontrar_data_disponivel(datas_aniversario[i], buscar_antes=False)\n",
    "        data_fim = encontrar_data_disponivel(datas_aniversario[i+1], buscar_antes=True)\n",
    "        \n",
    "        # Só processar se a data de fim é posterior à data de início\n",
    "        if data_fim <= data_inicio:\n",
    "            continue\n",
    "        \n",
    "        # Obter a volatilidade YTD para a data de fim\n",
    "        volatilidade_ytd = df_vol.loc[data_fim, 'volatilidade_ytd']\n",
    "        \n",
    "        # Calcular a volatilidade para este período específico\n",
    "        mask = (df_retornos.index >= data_inicio) & (df_retornos.index <= data_fim)\n",
    "        retornos_periodo = df_retornos.loc[mask, 'retorno_diario'].dropna()\n",
    "        \n",
    "        if len(retornos_periodo) > 1:\n",
    "            vol_diaria = np.std(retornos_periodo, ddof=1)\n",
    "            vol_anualizada = vol_diaria * np.sqrt(janela_anualizada)\n",
    "        else:\n",
    "            vol_anualizada = np.nan\n",
    "        \n",
    "        # Adicionar aos resultados\n",
    "        resultados.append({\n",
    "            'Período': f\"Ano {i+1}\",\n",
    "            'Data Início': data_inicio,\n",
    "            'Data Fim': data_fim,\n",
    "            'Volatilidade YTD': volatilidade_ytd,\n",
    "            'Volatilidade Período': vol_anualizada,\n",
    "            'Dias no Período': (data_fim - data_inicio).days + 1\n",
    "        })\n",
    "    \n",
    "    # Criar um DataFrame com os resultados\n",
    "    df_volatilidade_anual = pd.DataFrame(resultados)\n",
    "    \n",
    "    # Substitui NaN por 0\n",
    "    df_volatilidade_anual = df_volatilidade_anual.fillna(0)\n",
    "    return df_volatilidade_anual\n",
    "\n",
    "# Exemplo de uso:\n",
    "data_inicial = data_escolhida  # Sua data inicial\n",
    "df_vol = calcular_volatilidade_ytd_diario_reset_anual(df_cota, data_inicial)\n",
    "df_volatilidade_anual = extrair_volatilidade_anual(df_vol, df_cota, data_inicial)\n",
    "print(df_vol)\n",
    "print(df_volatilidade_anual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b903cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Período Data Início   Data Fim  Dias no Período  Pct Dias Alta  \\\n",
      "0   Ano 1  2020-09-02 2021-09-02              262       0.545802   \n",
      "1   Ano 2  2021-09-02 2022-09-02              262       0.530534   \n",
      "2   Ano 3  2022-09-02 2023-09-01              261       0.582375   \n",
      "3   Ano 4  2023-09-04 2024-09-02              261       0.624521   \n",
      "4   Ano 5  2024-09-02 2025-03-31              151       0.596026   \n",
      "\n",
      "   Pct Dias Baixa  \n",
      "0        0.454198  \n",
      "1        0.469466  \n",
      "2        0.417625  \n",
      "3        0.375479  \n",
      "4        0.403974  \n",
      "  Período Data Início   Data Fim  Correlacao c/ IBOV\n",
      "0   Ano 1  2020-09-02 2021-09-02           -0.172330\n",
      "1   Ano 2  2021-09-02 2022-09-02            0.091137\n",
      "2   Ano 3  2022-09-02 2023-09-01           -0.037988\n",
      "3   Ano 4  2023-09-04 2024-09-02           -0.150773\n",
      "4   Ano 5  2024-09-02 2025-03-31            0.045937\n",
      "  Período Data Início   Data Fim  Dias no Período  Pct Dias Alta  \\\n",
      "0   Ano 1  2020-09-02 2021-09-02              262       0.545802   \n",
      "1   Ano 2  2021-09-02 2022-09-02              262       0.530534   \n",
      "2   Ano 3  2022-09-02 2023-09-01              261       0.582375   \n",
      "3   Ano 4  2023-09-04 2024-09-02              261       0.624521   \n",
      "4   Ano 5  2024-09-02 2025-03-31              151       0.596026   \n",
      "\n",
      "   Pct Dias Baixa  \n",
      "0        0.454198  \n",
      "1        0.469466  \n",
      "2        0.417625  \n",
      "3        0.375479  \n",
      "4        0.403974  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "def calcular_retorno_anualizado_diario(df_cota, data_inicial=None):\n",
    "    \"\"\"\n",
    "    Calcula retorno anualizado diário reiniciando a cada 'aniversário' de data_inicial.\n",
    "\n",
    "    Args:\n",
    "        df_cota: DataFrame com coluna 'cota' e DatetimeIndex.\n",
    "        data_inicial: str ou datetime. Se None, usa primeira data do df_cota.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame com colunas:\n",
    "            - retorno_diario\n",
    "            - retorno_periodo\n",
    "            - retorno_anualizado\n",
    "    \"\"\"\n",
    "    if not isinstance(df_cota.index, pd.DatetimeIndex):\n",
    "        df_cota.index = pd.to_datetime(df_cota.index)\n",
    "\n",
    "    if data_inicial is None:\n",
    "        data_inicial = df_cota.index[0]\n",
    "    else:\n",
    "        data_inicial = pd.to_datetime(data_inicial)\n",
    "        posteriores = df_cota.index[df_cota.index >= data_inicial]\n",
    "        if len(posteriores) > 0:\n",
    "            data_inicial = posteriores[0]\n",
    "        else:\n",
    "            raise ValueError(\"data_inicial fora do range de df_cota\")\n",
    "\n",
    "    dia_ref, mes_ref = int(data_inicial.day), int(data_inicial.month)\n",
    "    df = df_cota.copy()\n",
    "    df['retorno_diario'] = df['cota'].pct_change()\n",
    "\n",
    "    def ano_janela(ts):\n",
    "        anos = ts.year - data_inicial.year\n",
    "        if (ts.month < mes_ref) or (ts.month == mes_ref and ts.day < dia_ref):\n",
    "            return anos\n",
    "        return anos + 1\n",
    "\n",
    "    df['ano_janela'] = df.index.map(ano_janela)\n",
    "\n",
    "    def inicio_janela(row):\n",
    "        ano = int(row['ano_janela'])\n",
    "        if ano <= 1:\n",
    "            return data_inicial\n",
    "        ano_cal = data_inicial.year + ano - 1\n",
    "        try:\n",
    "            dt0 = datetime(ano_cal, mes_ref, dia_ref)\n",
    "        except ValueError:\n",
    "            dt0 = datetime(ano_cal, mes_ref, 28)\n",
    "        while dt0 not in df.index and dt0 <= row.name:\n",
    "            dt0 += timedelta(days=1)\n",
    "        return dt0\n",
    "\n",
    "    df['data_inicio_janela'] = df.apply(inicio_janela, axis=1)\n",
    "\n",
    "    registros = []\n",
    "    for ts, row in df.iterrows():\n",
    "        dt0 = row['data_inicio_janela']\n",
    "        dias = (ts - dt0).days + 1\n",
    "        seg = df.loc[dt0:ts, 'retorno_diario'].dropna()\n",
    "        if len(seg) > 0:\n",
    "            ret_per = seg.add(1).prod() - 1\n",
    "            ret_ann = (1 + ret_per) ** (365 / dias) - 1\n",
    "        else:\n",
    "            ret_per = np.nan\n",
    "            ret_ann = np.nan\n",
    "        registros.append({'retorno_periodo': ret_per,\n",
    "                          'retorno_anualizado': ret_ann})\n",
    "\n",
    "    df_rets = pd.DataFrame(registros, index=df.index)\n",
    "    resultado = pd.concat([df[['retorno_diario']], df_rets], axis=1)\n",
    "    resultado = resultado.fillna(0)\n",
    "    return resultado\n",
    "\n",
    "\n",
    "def calcular_pct_dias_alta_baixa(df_retorno_diario, data_inicial=None):\n",
    "    \"\"\"\n",
    "    Calcula porcentagem de dias de alta e dias de baixa em janelas anuais a partir de data_inicial.\n",
    "\n",
    "    Args:\n",
    "        df_retorno_diario: DataFrame com coluna 'retorno_diario' e DatetimeIndex.\n",
    "        data_inicial: str ou datetime. Se None, usa primeira data do índice.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame com colunas:\n",
    "            - Período\n",
    "            - Data Início\n",
    "            - Data Fim\n",
    "            - Dias no Período\n",
    "            - Pct Dias Alta\n",
    "            - Pct Dias Baixa\n",
    "    \"\"\"\n",
    "    if not isinstance(df_retorno_diario.index, pd.DatetimeIndex):\n",
    "        df_retorno_diario.index = pd.to_datetime(df_retorno_diario.index)\n",
    "\n",
    "    if data_inicial is None:\n",
    "        data_inicial = df_retorno_diario.index[0]\n",
    "    else:\n",
    "        data_inicial = pd.to_datetime(data_inicial)\n",
    "        posteriores = df_retorno_diario.index[df_retorno_diario.index >= data_inicial]\n",
    "        if len(posteriores) > 0:\n",
    "            data_inicial = posteriores[0]\n",
    "        else:\n",
    "            raise ValueError(\"data_inicial fora do range de df_retorno_diario\")\n",
    "\n",
    "    dia_ref, mes_ref = int(data_inicial.day), int(data_inicial.month)\n",
    "    datas_aniv = []\n",
    "    ano = data_inicial.year\n",
    "    while True:\n",
    "        try:\n",
    "            aniv = datetime(ano, mes_ref, dia_ref)\n",
    "        except ValueError:\n",
    "            aniv = datetime(ano, mes_ref, 28)\n",
    "        if df_retorno_diario.index.min() <= aniv <= df_retorno_diario.index.max():\n",
    "            datas_aniv.append(aniv)\n",
    "        ano += 1\n",
    "        try:\n",
    "            proxima = datetime(ano, mes_ref, min(dia_ref, 28))\n",
    "        except ValueError:\n",
    "            proxima = datetime(ano, mes_ref, 28)\n",
    "        if proxima > df_retorno_diario.index.max():\n",
    "            break\n",
    "    if datas_aniv and df_retorno_diario.index.max() > datas_aniv[-1]:\n",
    "        datas_aniv.append(df_retorno_diario.index.max())\n",
    "    if len(datas_aniv) < 2:\n",
    "        raise ValueError(\"Não há janelas anuais completas nos dados fornecidos\")\n",
    "\n",
    "    def prox_data(data, antes=True):\n",
    "        if data in df_retorno_diario.index:\n",
    "            return data\n",
    "        if antes:\n",
    "            ant = df_retorno_diario.index[df_retorno_diario.index < data]\n",
    "            if len(ant) > 0:\n",
    "                return ant[-1]\n",
    "        pos = df_retorno_diario.index[df_retorno_diario.index > data]\n",
    "        if len(pos) > 0:\n",
    "            return pos[0]\n",
    "        return df_retorno_diario.index[0] if antes else df_retorno_diario.index[-1]\n",
    "\n",
    "    resultados = []\n",
    "    for i in range(len(datas_aniv) - 1):\n",
    "        dt_i = prox_data(datas_aniv[i], antes=False)\n",
    "        dt_f = prox_data(datas_aniv[i+1], antes=True)\n",
    "        if dt_f <= dt_i:\n",
    "            continue\n",
    "        mask = (df_retorno_diario.index >= dt_i) & (df_retorno_diario.index <= dt_f)\n",
    "        total = mask.sum()\n",
    "        series = df_retorno_diario.loc[mask, 'retorno_diario']\n",
    "        up = (series > 0).sum()\n",
    "        down = (series < 0).sum()\n",
    "        pct_up = up / total if total > 0 else np.nan\n",
    "        pct_down = down / total if total > 0 else np.nan\n",
    "        resultados.append({\n",
    "            'Período': f\"Ano {i+1}\",\n",
    "            'Data Início': dt_i,\n",
    "            'Data Fim': dt_f,\n",
    "            'Dias no Período': total,\n",
    "            'Pct Dias Alta': pct_up,\n",
    "            'Pct Dias Baixa': pct_down\n",
    "        })\n",
    "    df_pct = pd.DataFrame(resultados)\n",
    "    return df_pct\n",
    "\n",
    "\n",
    "# Uso:\n",
    "pct_dias = calcular_pct_dias_alta_baixa(df_retorno_diario, data_escolhida)\n",
    "print(pct_dias)\n",
    "\n",
    "# Correlação anual entre fundo e IBOV:\n",
    "def calcular_correlacao_fundo_ibov(df_retorno_diario, df_perf_ibov, data_inicial=None):\n",
    "    \"\"\"\n",
    "    Calcula a correlação dos retornos diários do fundo com o IBOV em janelas anuais a partir de data_inicial.\n",
    "\n",
    "    Args:\n",
    "        df_retorno_diario: DataFrame com coluna 'retorno_diario' e DatetimeIndex.\n",
    "        df_perf_ibov: DataFrame com coluna 'IBOV' e mesmo DateTimeIndex.\n",
    "        data_inicial: str ou datetime. Se None, usa primeira data do índice de df_retorno_diario.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame com colunas:\n",
    "            - Período\n",
    "            - Data Início\n",
    "            - Data Fim\n",
    "            - Correlacao\n",
    "    \"\"\"\n",
    "    # índices datetime\n",
    "    if not isinstance(df_retorno_diario.index, pd.DatetimeIndex):\n",
    "        df_retorno_diario.index = pd.to_datetime(df_retorno_diario.index)\n",
    "    if not isinstance(df_perf_ibov.index, pd.DatetimeIndex):\n",
    "        df_perf_ibov.index = pd.to_datetime(df_perf_ibov.index)\n",
    "\n",
    "    # alinhar índices\n",
    "    df_corr = pd.concat([df_retorno_diario['retorno_diario'], df_perf_ibov['IBOV']], axis=1, join='inner')\n",
    "    df_corr = df_corr.dropna()\n",
    "\n",
    "    # data_inicial\n",
    "    if data_inicial is None:\n",
    "        data_inicial = df_corr.index[0]\n",
    "    else:\n",
    "        data_inicial = pd.to_datetime(data_inicial)\n",
    "        posteriores = df_corr.index[df_corr.index >= data_inicial]\n",
    "        if len(posteriores) > 0:\n",
    "            data_inicial = posteriores[0]\n",
    "        else:\n",
    "            raise ValueError(\"data_inicial fora do range do DataFrame combinado\")\n",
    "\n",
    "    dia_ref, mes_ref = int(data_inicial.day), int(data_inicial.month)\n",
    "    datas_aniv = []\n",
    "    ano = data_inicial.year\n",
    "    # gera aniversários\n",
    "    while True:\n",
    "        try:\n",
    "            aniv = datetime(ano, mes_ref, dia_ref)\n",
    "        except ValueError:\n",
    "            aniv = datetime(ano, mes_ref, 28)\n",
    "        if df_corr.index.min() <= aniv <= df_corr.index.max():\n",
    "            datas_aniv.append(aniv)\n",
    "        ano += 1\n",
    "        try:\n",
    "            prox = datetime(ano, mes_ref, min(dia_ref, 28))\n",
    "        except ValueError:\n",
    "            prox = datetime(ano, mes_ref, 28)\n",
    "        if prox > df_corr.index.max():\n",
    "            break\n",
    "    if datas_aniv and df_corr.index.max() > datas_aniv[-1]:\n",
    "        datas_aniv.append(df_corr.index.max())\n",
    "    if len(datas_aniv) < 2:\n",
    "        raise ValueError(\"Não há janelas anuais completas nos dados fornecidos\")\n",
    "\n",
    "    # função para encontrar data válida\n",
    "    def prox_data(data, antes=True):\n",
    "        if data in df_corr.index:\n",
    "            return data\n",
    "        if antes:\n",
    "            ant = df_corr.index[df_corr.index < data]\n",
    "            if len(ant) > 0:\n",
    "                return ant[-1]\n",
    "        pos = df_corr.index[df_corr.index > data]\n",
    "        if len(pos) > 0:\n",
    "            return pos[0]\n",
    "        return df_corr.index[0] if antes else df_corr.index[-1]\n",
    "\n",
    "    resultados = []\n",
    "    for i in range(len(datas_aniv)-1):\n",
    "        dt_i = prox_data(datas_aniv[i], antes=False)\n",
    "        dt_f = prox_data(datas_aniv[i+1], antes=True)\n",
    "        if dt_f <= dt_i:\n",
    "            continue\n",
    "        mask = (df_corr.index >= dt_i) & (df_corr.index <= dt_f)\n",
    "        sub = df_corr.loc[mask]\n",
    "        corr = sub['retorno_diario'].corr(sub['IBOV'])\n",
    "        resultados.append({\n",
    "            'Período': f\"Ano {i+1}\",\n",
    "            'Data Início': dt_i,\n",
    "            'Data Fim': dt_f,\n",
    "            'Correlacao c/ IBOV': corr\n",
    "        })\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "correlacoes = calcular_correlacao_fundo_ibov(df_retorno_diario, df_perf_ibov, data_escolhida)\n",
    "print(correlacoes)\n",
    "pct_dias = calcular_pct_dias_alta_baixa(df_retorno_diario, data_escolhida)\n",
    "print(pct_dias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6e069020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Data Início   Data Fim Retorno    CDI    Vol Sharpe Sortino  \\\n",
      "Período                                                               \n",
      "Ano 1    2020-09-02 2021-09-02   22.6%   2.9%   9.9%   1.98    2.96   \n",
      "Ano 2    2021-09-02 2022-09-02   37.6%  10.4%  10.6%   2.56    4.59   \n",
      "Ano 3    2022-09-02 2023-09-01   22.5%  13.9%   8.2%   1.04    1.71   \n",
      "Ano 4    2023-09-04 2024-09-02   35.2%  11.8%   7.4%   3.17    5.10   \n",
      "Ano 5    2024-09-02 2025-03-31   19.0%  12.3%   7.2%   0.93    1.40   \n",
      "Total    2020-09-02 2025-03-31   27.4%  10.3%   8.7%   1.94    3.15   \n",
      "\n",
      "        Pct Dias Alta Pct Dias Baixa Correlacao c/ IBOV Gap CDI    \\\n",
      "Período                                                             \n",
      "Ano 1           54.6%          45.4%              -0.17   19.6%     \n",
      "Ano 2           53.1%          46.9%               0.09   27.3%     \n",
      "Ano 3           58.2%          41.8%              -0.04    8.6%     \n",
      "Ano 4           62.5%          37.5%              -0.15   23.4%     \n",
      "Ano 5           59.6%          40.4%               0.05    6.7%     \n",
      "Total           57.6%          42.4%              -0.04   17.1%     \n",
      "\n",
      "                 Label Drawdown %  \n",
      "Período                            \n",
      "Ano 1              <1%      63.3%  \n",
      "Ano 2    entre 1% e 2%      18.4%  \n",
      "Ano 3    entre 2% e 3%       9.9%  \n",
      "Ano 4    entre 3% e 4%       5.4%  \n",
      "Ano 5    entre 4% e 5%       2.5%  \n",
      "Total              >5%       0.5%  \n",
      "\n",
      "Soma dos percentuais de drawdown: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === CÉLULA DE RESUMO \"LS\" ===\n",
    "# 1) Extrai indicadores anuais já calculados\n",
    "ret = extrair_retornos_anuais(df_ytd, df_cota, df_perf_cdi, data_escolhida)\n",
    "# renomeia para trabalhar com annualizados\n",
    "ret = ret.set_index('Período')\n",
    "ret.rename(columns={'Retorno Anualizado':'Retorno','CDI Anualizado':'CDI'}, inplace=True)\n",
    "# extrai datas\n",
    "datas = ret[['Data Início','Data Fim']]\n",
    "# volatilidade anualizada por período\n",
    "vol = extrair_volatilidade_anual(\n",
    "    calcular_volatilidade_ytd_diario_reset_anual(df_cota, data_escolhida),\n",
    "    df_cota, data_escolhida\n",
    ").set_index('Período')\n",
    "vol = vol[['Volatilidade Período']].rename(columns={'Volatilidade Período':'Vol'})\n",
    "# correlação c/ IBOV\n",
    "corr = calcular_correlacao_fundo_ibov(df_retorno_diario, df_perf_ibov, data_escolhida)\n",
    "corr = corr.set_index('Período')[['Correlacao c/ IBOV']]\n",
    "# sharpe: (Retorno - CDI)/Vol\n",
    "shp = pd.DataFrame(index=ret.index)\n",
    "shp['Sharpe'] = (ret['Retorno'] - ret['CDI']) / vol['Vol']\n",
    "# sortino: (Retorno - CDI)/(downside annualizada)\n",
    "annual_factor = 252\n",
    "sortino = []\n",
    "for per in ret.index:\n",
    "    start = ret.loc[per, 'Data Início']\n",
    "    end   = ret.loc[per, 'Data Fim']\n",
    "    seg   = df_retorno_diario.loc[(df_retorno_diario.index>start)&(df_retorno_diario.index<=end), 'retorno_diario']\n",
    "    down_std = seg[seg<0].std(ddof=1) * np.sqrt(annual_factor)\n",
    "    value = (ret.loc[per,'Retorno'] - ret.loc[per,'CDI']) / down_std if down_std>0 else np.nan\n",
    "    sortino.append(value)\n",
    "srt = pd.DataFrame({'Sortino': sortino}, index=ret.index)\n",
    "# pct dias alta/baixa\n",
    "pct = calcular_pct_dias_alta_baixa(df_retorno_diario, data_escolhida).set_index('Período')\n",
    "# 2) Compor DataFrame LS\n",
    "frames = [\n",
    "    datas,\n",
    "    ret[['Retorno','CDI']],\n",
    "    vol,\n",
    "    shp,\n",
    "    srt,\n",
    "    pct[['Pct Dias Alta','Pct Dias Baixa']],\n",
    "    corr\n",
    "]\n",
    "df_LS = pd.concat(frames, axis=1)\n",
    "# 3) Gap CDI\n",
    "df_LS['Gap CDI'] = df_LS['Retorno'] - df_LS['CDI']\n",
    "\n",
    "# 4) Adicionar coluna vazia\n",
    "df_LS[''] = ''\n",
    "\n",
    "# 5) Definir os rótulos para cada linha\n",
    "drawdown_labels = {\n",
    "    'Ano 1': '<1%',\n",
    "    'Ano 2': 'entre 1% e 2%',\n",
    "    'Ano 3': 'entre 2% e 3%',\n",
    "    'Ano 4': 'entre 3% e 4%',\n",
    "    'Ano 5': 'entre 4% e 5%',\n",
    "    'Total': '>5%'\n",
    "}\n",
    "\n",
    "# 6) Calcular percentuais de drawdown - CORREÇÃO para totalizar 100%\n",
    "drawdown_valores = {}\n",
    "\n",
    "# Definir os intervalos de drawdown para cada rótulo\n",
    "intervalos = {\n",
    "    'Ano 1': (-0.01, 0),         # <1%\n",
    "    'Ano 2': (-0.02, -0.01),     # entre 1% e 2%\n",
    "    'Ano 3': (-0.03, -0.02),     # entre 2% e 3%\n",
    "    'Ano 4': (-0.04, -0.03),     # entre 3% e 4%\n",
    "    'Ano 5': (-0.05, -0.04),     # entre 4% e 5%\n",
    "    'Total': (-float('inf'), -0.05)  # >5%\n",
    "}\n",
    "\n",
    "# Calcular o percentual total de dias em todos os períodos\n",
    "# em que o drawdown esteve dentro de cada intervalo específico\n",
    "total_dias = len(df_drawdown)\n",
    "dias_por_intervalo = {\n",
    "    'Ano 1': 0,\n",
    "    'Ano 2': 0,\n",
    "    'Ano 3': 0,\n",
    "    'Ano 4': 0,\n",
    "    'Ano 5': 0,\n",
    "    'Total': 0\n",
    "}\n",
    "\n",
    "# Classificar cada dia do drawdown em um dos intervalos\n",
    "for i, row in df_drawdown.iterrows():\n",
    "    value = row['Drawdown']\n",
    "    \n",
    "    # Verificar em qual intervalo este valor se encaixa\n",
    "    for periodo, (limite_inf, limite_sup) in intervalos.items():\n",
    "        if periodo == 'Total':  # Para o intervalo >5%\n",
    "            if value <= limite_sup:\n",
    "                dias_por_intervalo[periodo] += 1\n",
    "                break\n",
    "        else:  # Para os demais intervalos\n",
    "            if limite_inf < value <= limite_sup:\n",
    "                dias_por_intervalo[periodo] += 1\n",
    "                break\n",
    "\n",
    "# Calcular percentuais\n",
    "for periodo in dias_por_intervalo:\n",
    "    percentual = (dias_por_intervalo[periodo] / total_dias * 100) if total_dias > 0 else 0\n",
    "    drawdown_valores[periodo] = f\"{percentual:.1f}%\"\n",
    "\n",
    "# 7) Adicionar as colunas de Label e Drawdown %\n",
    "df_LS['Label'] = pd.Series(drawdown_labels, index=df_LS.index)\n",
    "df_LS['Drawdown %'] = pd.Series(drawdown_valores, index=df_LS.index)\n",
    "\n",
    "# 8) Calcular a linha Total como média para colunas numéricas\n",
    "tot = df_LS.mean(numeric_only=True)\n",
    "tot.name = 'Total'\n",
    "\n",
    "# Preservar as colunas não numéricas na linha Total\n",
    "non_numeric_cols = ['Data Início', 'Data Fim', '', 'Label', 'Drawdown %']\n",
    "for col in non_numeric_cols:\n",
    "    if col in df_LS.columns:\n",
    "        if col == 'Label':\n",
    "            tot[col] = '>5%'  # Definir o rótulo da linha Total\n",
    "        elif col == 'Drawdown %':\n",
    "            # Usar o valor já calculado para o Total\n",
    "            tot[col] = drawdown_valores['Total']\n",
    "        elif col == 'Data Início':\n",
    "            tot[col] = df_drawdown.index.min()  # Primeira data do drawdown\n",
    "        elif col == 'Data Fim':\n",
    "            tot[col] = df_drawdown.index.max()  # Última data do drawdown\n",
    "        else:\n",
    "            tot[col] = ''\n",
    "\n",
    "# Adicionar a linha Total ao DataFrame\n",
    "df_LS.loc['Total'] = tot\n",
    "\n",
    "# 9) Formatação\n",
    "# percentuais (Retorno, CDI, Gap CDI, Vol, pct dias) com 1 casa e %\n",
    "for col in ['Retorno', 'CDI', 'Gap CDI', 'Vol', 'Pct Dias Alta', 'Pct Dias Baixa']:\n",
    "    df_LS[col] = df_LS[col].apply(lambda x: f\"{float(str(x).replace('%', '')):.1f}%\" if isinstance(x, str) else f\"{x*100:.1f}%\")\n",
    "\n",
    "# Sharpe e Sortino com 2 casas decimais\n",
    "for col in ['Sharpe', 'Sortino']:\n",
    "    df_LS[col] = df_LS[col].apply(lambda x: f\"{float(x):.2f}\" if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# correlação numérica com 2 casas decimais\n",
    "df_LS['Correlacao c/ IBOV'] = df_LS['Correlacao c/ IBOV'].apply(lambda x: f\"{float(x):.2f}\" if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Exibir a tabela\n",
    "print(df_LS)\n",
    "\n",
    "# Verificar se os percentuais totalizam 100%\n",
    "total_perc = sum([float(valor.replace('%', '')) for valor in drawdown_valores.values()])\n",
    "print(f\"\\nSoma dos percentuais de drawdown: {total_perc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d0cf35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f484e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizações adicionais no notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# Assumindo que df_ytd, df_cota, df_perf_cdi, df_retorno_diario,\n",
    "# df_perf_ibov, df_drawdown e funções já estão definidos no notebook\n",
    "\n",
    "display(df_LS)\n",
    "\n",
    "# Parâmetro padrão\n",
    "data0 = data_escolhida\n",
    "\n",
    "# Garantir que data_escolhida seja datetime\n",
    "if isinstance(data_escolhida, str):\n",
    "    data_escolhida = pd.to_datetime(data_escolhida)\n",
    "\n",
    "# Filtrar todos os dataframes a partir da data_escolhida\n",
    "df_cota = df_cota[df_cota.index >= data_escolhida]\n",
    "df_perf_cdi = df_perf_cdi[df_perf_cdi.index >= data_escolhida]\n",
    "df_retorno_diario = df_retorno_diario[df_retorno_diario.index >= data_escolhida]\n",
    "df_vol_252 = df_vol_252[df_vol_252.index >= data_escolhida]\n",
    "df_drawdown = df_drawdown[df_drawdown.index >= data_escolhida]\n",
    "\n",
    "# Verificar o tipo do índice de df_LS antes de filtrar\n",
    "if 'df_LS' in locals():\n",
    "    if df_LS.index.dtype == 'object':  # Se for string\n",
    "        if isinstance(data_escolhida, pd.Timestamp):\n",
    "            data_escolhida_str = data_escolhida.strftime('%Y-%m-%d')\n",
    "            df_LS = df_LS[df_LS.index >= data_escolhida_str]\n",
    "    else:  # Se for datetime\n",
    "        df_LS = df_LS[df_LS.index >= data_escolhida]\n",
    "\n",
    "# Função auxiliar para janelas móveis\n",
    "def rolling_metrics(df, window_days=252):\n",
    "    ret = df['retorno_diario'].rolling(window_days).apply(lambda x: np.prod(x+1)-1)\n",
    "    vol = df['retorno_diario'].rolling(window_days).std(ddof=1) * np.sqrt(window_days)\n",
    "    return pd.DataFrame({'ret_rol': ret, 'vol_rol': vol})\n",
    "\n",
    "# 1) Performance acumulada: Fundo vs CDI\n",
    "# Recalcular os retornos a partir da data_escolhida\n",
    "perf_fundo = df_cota['cota'] / df_cota['cota'].iloc[0] - 1\n",
    "perf_cdi = df_perf_cdi['CDI'].cumprod() - 1\n",
    "df_perf = pd.DataFrame({'Fundo': perf_fundo, 'CDI': perf_cdi})\n",
    "\n",
    "# Formato para data em string para exibição\n",
    "data_escolhida_str = data_escolhida.strftime(\"%d/%m/%Y\") if hasattr(data_escolhida, 'strftime') else data_escolhida\n",
    "\n",
    "fig1 = px.line(df_perf, x=df_perf.index, y=['Fundo','CDI'], \n",
    "               title=f'Performance Acumulada: Fundo vs CDI (desde {data_escolhida_str})')\n",
    "fig1.update_layout(\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    margin=dict(l=40, r=40, t=60, b=40)\n",
    ")\n",
    "# Adicionar sombreamento sob as linhas\n",
    "fig1.data[0].fill = 'tozeroy'\n",
    "fig1.data[0].fillcolor = 'rgba(55, 126, 184, 0.2)'\n",
    "fig1.data[1].fill = 'tozeroy'\n",
    "fig1.data[1].fillcolor = 'rgba(77, 175, 74, 0.2)'\n",
    "\n",
    "# Adicionar anotações com retornos finais\n",
    "fig1.add_annotation(\n",
    "    x=df_perf.index[-1], y=df_perf['Fundo'].iloc[-1],\n",
    "    text=f\"{df_perf['Fundo'].iloc[-1]:.2%}\",\n",
    "    showarrow=True, arrowhead=1\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# 2) Volatilidade mensal anualizada ao longo do tempo\n",
    "# Calcular as médias com base nos dados filtrados\n",
    "vol_mean = df_vol_252['volatilidade_252'].mean()\n",
    "    \n",
    "# Filtrar para datas a partir de setembro de 2020 (apenas se data_escolhida for anterior)\n",
    "min_date = max(pd.Timestamp('2020-09-01'), data_escolhida)\n",
    "df_pos_set2020 = df_vol_252[df_vol_252.index >= min_date]\n",
    "vol_mean_set2020 = df_pos_set2020['volatilidade_252'].mean() if not df_pos_set2020.empty else vol_mean\n",
    "\n",
    "# Criar figura base\n",
    "fig2 = go.Figure()\n",
    "\n",
    "# Adicionar linha principal de volatilidade\n",
    "fig2.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_vol_252.index,\n",
    "        y=df_vol_252['volatilidade_252'],\n",
    "        mode='lines',\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(31, 119, 180, 0.2)',\n",
    "        line=dict(color='rgba(31, 119, 180, 1)'),\n",
    "        name='Volatilidade'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Adicionar linha da média geral (vermelha)\n",
    "fig2.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[df_vol_252.index.min(), df_vol_252.index.max()],\n",
    "        y=[vol_mean, vol_mean],\n",
    "        mode='lines',\n",
    "        line=dict(color='red', dash='dash'),\n",
    "        name=f'Média: {vol_mean:.2%}'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Adicionar linha da média pós setembro 2020 (verde) - apenas se relevante\n",
    "if min_date > data_escolhida and not df_pos_set2020.empty:\n",
    "    fig2.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[df_pos_set2020.index.min(), df_vol_252.index.max()],\n",
    "            y=[vol_mean_set2020, vol_mean_set2020],\n",
    "            mode='lines',\n",
    "            line=dict(color='green', dash='dash'),\n",
    "            name=f'Média pós-Set/2020: {vol_mean_set2020:.2%}'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Ajustar o layout do gráfico\n",
    "fig2.update_layout(\n",
    "    title={\n",
    "        'text': f'Volatilidade Móvel de 21 Dias (Anualizada) (desde {data_escolhida_str})',\n",
    "        'x': 0.5,  # Centralizar o título\n",
    "        'xanchor': 'center'\n",
    "    },\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    yaxis_title='Volatilidade Anualizada',\n",
    "    legend=dict(\n",
    "        orientation='h',          # Orientação horizontal\n",
    "        yanchor='top',            # Ancorar no topo\n",
    "        y=-0.15,                  # Posição abaixo do gráfico\n",
    "        xanchor='center',         # Ancorar no centro\n",
    "        x=0.5                     # Posição centralizada\n",
    "    )\n",
    ")\n",
    "\n",
    "# Exibir o gráfico\n",
    "fig2.show()\n",
    "\n",
    "\n",
    "\n",
    "# 4) Drawdown e tempo de recuperação\n",
    "dd = df_drawdown.copy()\n",
    "fig4 = px.area(dd.reset_index(), x='Data', y='Drawdown',\n",
    "               title=f'Drawdown Diário do Fundo (desde {data_escolhida_str})')\n",
    "fig4.update_traces(\n",
    "    line_color='rgba(178, 34, 34, 0.8)',\n",
    "    fillcolor='rgba(178, 34, 34, 0.3)'\n",
    ")\n",
    "fig4.update_layout(\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(\n",
    "        tickformat='.1%',\n",
    "        title='Drawdown'\n",
    "    )\n",
    ")\n",
    "# Adiciona linhas de referência\n",
    "fig4.add_hline(y=-0.05, line_dash=\"dash\", line_color=\"orange\", \n",
    "               annotation_text=\"-5%\", annotation_position=\"bottom right\")\n",
    "fig4.add_hline(y=-0.10, line_dash=\"dash\", line_color=\"red\", \n",
    "               annotation_text=\"-10%\", annotation_position=\"bottom right\")\n",
    "fig4.show()\n",
    "\n",
    "# Gráfico de duração de drawdowns (queda + recuperação)\n",
    "events = []\n",
    "start_date = None\n",
    "for idx, row in dd.iterrows():\n",
    "    if row['Drawdown'] < 0 and start_date is None:\n",
    "        start_date = idx\n",
    "    if row['Drawdown'] == 0 and start_date is not None:\n",
    "        recovery = idx\n",
    "        duration = (recovery - start_date).days\n",
    "        events.append({'Início': start_date, 'Recuperação': recovery, 'Duração': duration})\n",
    "        start_date = None\n",
    "df_events = pd.DataFrame(events)\n",
    "if not df_events.empty:\n",
    "    fig4b = px.bar(df_events, x='Início', y='Duração',\n",
    "                  title=f'Duração de Drawdown e Recuperação (desde {data_escolhida_str})')\n",
    "    fig4b.show()\n",
    "\n",
    "# 7) Histograma de retornos diário, semanal, mensal\n",
    "_df = df_retorno_diario.copy()\n",
    "_df['ret_sem'] = _df['retorno_diario'].rolling(5).apply(lambda x: np.prod(x+1)-1)\n",
    "_df['ret_mes'] = _df['retorno_diario'].rolling(21).apply(lambda x: np.prod(x+1)-1)\n",
    "fig7 = make_subplots(rows=3, cols=1, \n",
    "                     subplot_titles=['Diário','Semanal','Mensal'])\n",
    "for i, col in enumerate(['retorno_diario','ret_sem','ret_mes'], start=1):\n",
    "    fig7.add_trace(go.Histogram(x=_df[col], name=col), row=i, col=1)\n",
    "fig7.update_layout(title=f'Distribuição de Retornos (desde {data_escolhida_str})')\n",
    "fig7.show()\n",
    "\n",
    "# 8) VaR e CVaR 252d rolling\n",
    "var = df_retorno_diario['retorno_diario'].rolling(252).quantile(0.01)\n",
    "cvar = df_retorno_diario['retorno_diario'].rolling(252).apply(\n",
    "    lambda x: x[x<=np.quantile(x,0.01)].mean()\n",
    ")\n",
    "df_risk = pd.DataFrame({'VaR': var, 'CVaR': cvar})\n",
    "fig8 = px.line(df_risk, x=df_risk.index, y=['VaR','CVaR'],\n",
    "               title=f'VaR e CVaR (1%) 252d Rolling (desde {data_escolhida_str})')\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0f1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
