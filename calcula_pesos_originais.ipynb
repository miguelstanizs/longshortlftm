{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8186c56",
   "metadata": {},
   "source": [
    "CALCULA OS PESOS DO PORTFÓLIO NOS INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "94be9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "peso_single_names = 1\n",
    "peso_indices = 1 - peso_single_names\n",
    "custo_rebalanceamento = 0.0003\n",
    "custo_ajuste = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "523f92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 172)\n",
      "1456\n",
      "IBOV:\n",
      "                     TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2019-09-03 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2019-09-04 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2019-09-05 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2019-09-06 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2025-03-25 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2025-03-26 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2025-03-27 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2025-03-28 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "2025-03-31 00:00:00      0      0    0.0    0.0    0.0    0.0      0    0.0   \n",
      "\n",
      "                     ESPA3  GGPS3  ...  ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  \\\n",
      "Data                               ...                                       \n",
      "2019-09-02 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2019-09-03 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2019-09-04 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2019-09-05 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2019-09-06 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "...                    ...    ...  ...     ...    ...    ...    ...    ...   \n",
      "2025-03-25 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2025-03-26 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2025-03-27 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2025-03-28 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "2025-03-31 00:00:00      0      0  ...       0    0.0      0      0      0   \n",
      "\n",
      "                     CVCB3  TASA4  GOLL4  EMBR3  Total_Ibov_%  \n",
      "Data                                                           \n",
      "2019-09-02 00:00:00    0.0      0    0.0    0.0      0.455378  \n",
      "2019-09-03 00:00:00    0.0      0    0.0    0.0      0.455220  \n",
      "2019-09-04 00:00:00    0.0      0    0.0    0.0      0.455615  \n",
      "2019-09-05 00:00:00    0.0      0    0.0    0.0      0.457521  \n",
      "2019-09-06 00:00:00    0.0      0    0.0    0.0      0.462855  \n",
      "...                    ...    ...    ...    ...           ...  \n",
      "2025-03-25 00:00:00    0.0      0    0.0    0.0      0.199304  \n",
      "2025-03-26 00:00:00    0.0      0    0.0    0.0      0.200229  \n",
      "2025-03-27 00:00:00    0.0      0    0.0    0.0      0.200270  \n",
      "2025-03-28 00:00:00    0.0      0    0.0    0.0      0.200717  \n",
      "2025-03-31 00:00:00    0.0      0    0.0    0.0      0.201265  \n",
      "\n",
      "[1456 rows x 172 columns]\n",
      "\n",
      "SMAL:\n",
      "                        TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  \\\n",
      "Data                                                                            \n",
      "2019-09-02 00:00:00  0.004461  0.000000    0.0    0.0    0.0    0.0  0.000000   \n",
      "2019-09-03 00:00:00  0.004410  0.000000    0.0    0.0    0.0    0.0  0.000000   \n",
      "2019-09-04 00:00:00  0.004467  0.000000    0.0    0.0    0.0    0.0  0.000000   \n",
      "2019-09-05 00:00:00  0.004347  0.000000    0.0    0.0    0.0    0.0  0.000000   \n",
      "2019-09-06 00:00:00  0.004290  0.000000    0.0    0.0    0.0    0.0  0.000000   \n",
      "...                       ...       ...    ...    ...    ...    ...       ...   \n",
      "2025-03-25 00:00:00  0.003904  0.002892    0.0    0.0    0.0    0.0  0.003855   \n",
      "2025-03-26 00:00:00  0.003780  0.002898    0.0    0.0    0.0    0.0  0.003963   \n",
      "2025-03-27 00:00:00  0.003729  0.002871    0.0    0.0    0.0    0.0  0.003996   \n",
      "2025-03-28 00:00:00  0.003769  0.002452    0.0    0.0    0.0    0.0  0.003953   \n",
      "2025-03-31 00:00:00  0.003859  0.002318    0.0    0.0    0.0    0.0  0.003863   \n",
      "\n",
      "                     CRFB3  ESPA3  GGPS3  ...    ALUP11  AZUL4  UNIP6  ORVR3  \\\n",
      "Data                                      ...                                  \n",
      "2019-09-02 00:00:00    0.0    0.0    0.0  ...  0.016202    0.0    0.0    0.0   \n",
      "2019-09-03 00:00:00    0.0    0.0    0.0  ...  0.016164    0.0    0.0    0.0   \n",
      "2019-09-04 00:00:00    0.0    0.0    0.0  ...  0.016429    0.0    0.0    0.0   \n",
      "2019-09-05 00:00:00    0.0    0.0    0.0  ...  0.016496    0.0    0.0    0.0   \n",
      "2019-09-06 00:00:00    0.0    0.0    0.0  ...  0.016562    0.0    0.0    0.0   \n",
      "...                    ...    ...    ...  ...       ...    ...    ...    ...   \n",
      "2025-03-25 00:00:00    0.0    0.0    0.0  ...  0.000000    0.0    0.0    0.0   \n",
      "2025-03-26 00:00:00    0.0    0.0    0.0  ...  0.000000    0.0    0.0    0.0   \n",
      "2025-03-27 00:00:00    0.0    0.0    0.0  ...  0.000000    0.0    0.0    0.0   \n",
      "2025-03-28 00:00:00    0.0    0.0    0.0  ...  0.000000    0.0    0.0    0.0   \n",
      "2025-03-31 00:00:00    0.0    0.0    0.0  ...  0.000000    0.0    0.0    0.0   \n",
      "\n",
      "                     AMBP3  CVCB3  TASA4  GOLL4  EMBR3  Total_Smal_%  \n",
      "Data                                                                  \n",
      "2019-09-02 00:00:00    0.0    0.0    0.0    0.0    0.0      0.241222  \n",
      "2019-09-03 00:00:00    0.0    0.0    0.0    0.0    0.0      0.242029  \n",
      "2019-09-04 00:00:00    0.0    0.0    0.0    0.0    0.0      0.240134  \n",
      "2019-09-05 00:00:00    0.0    0.0    0.0    0.0    0.0      0.238785  \n",
      "2019-09-06 00:00:00    0.0    0.0    0.0    0.0    0.0      0.238705  \n",
      "...                    ...    ...    ...    ...    ...           ...  \n",
      "2025-03-25 00:00:00    0.0    0.0    0.0    0.0    0.0      0.247482  \n",
      "2025-03-26 00:00:00    0.0    0.0    0.0    0.0    0.0      0.247685  \n",
      "2025-03-27 00:00:00    0.0    0.0    0.0    0.0    0.0      0.245099  \n",
      "2025-03-28 00:00:00    0.0    0.0    0.0    0.0    0.0      0.245447  \n",
      "2025-03-31 00:00:00    0.0    0.0    0.0    0.0    0.0      0.245287  \n",
      "\n",
      "[1456 rows x 172 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leitura dos arquivos Excel\n",
    "df_port_comp = pd.read_excel('port_comp.xlsx', index_col=0)\n",
    "df_peso_ibov = pd.read_excel('peso_ibov.xlsx', index_col=0)\n",
    "df_peso_smal = pd.read_excel('peso_smal.xlsx', header=0)\n",
    "\n",
    "# Remove a primeira coluna (Unnamed: 0) que só tem NaN\n",
    "if 'Unnamed: 0' in df_peso_smal.columns:\n",
    "    df_peso_smal = df_peso_smal.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Define a coluna 'Data' como índice e converte para datetime64\n",
    "df_peso_smal['Data'] = pd.to_datetime(df_peso_smal['Data'])\n",
    "df_peso_smal.set_index('Data', inplace=True)\n",
    "# agora o índice é DatetimeIndex, sem .date\n",
    "\n",
    "# Preenche valores NaN com zeros\n",
    "df_port_comp.fillna(0, inplace=True)\n",
    "df_peso_ibov.fillna(0, inplace=True)\n",
    "df_peso_smal.fillna(0, inplace=True)\n",
    "\n",
    "# Alinha (reindexa) e já preenche eventuais datas faltantes\n",
    "df_peso_ibov = df_peso_ibov.reindex(df_port_comp.index).fillna(0)\n",
    "df_peso_smal = df_peso_smal.reindex(df_port_comp.index).fillna(0)\n",
    "\n",
    "# Multiplica elemento a elemento\n",
    "df_peso_port_ibov = df_port_comp * df_peso_ibov\n",
    "df_peso_port_smal = df_port_comp * df_peso_smal\n",
    "\n",
    "# Soma totais\n",
    "df_peso_port_ibov['Total_Ibov_%'] = df_peso_port_ibov.sum(axis=1)\n",
    "df_peso_port_smal['Total_Smal_%'] = df_peso_port_smal.sum(axis=1)\n",
    "\n",
    "print(df_peso_port_ibov.shape)        # (n_linhas, n_colunas)\n",
    "print(df_peso_port_ibov.index.nunique())\n",
    "\n",
    "\n",
    "print(\"IBOV:\")\n",
    "print(df_peso_port_ibov)\n",
    "print(\"\\nSMAL:\")\n",
    "print(df_peso_port_smal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595a556",
   "metadata": {},
   "source": [
    "Long Indices IBOV e SMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ae4390aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_long_indices_ibov:\n",
      "               TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.020947  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-03  0.020953  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-04  0.020938  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-05  0.020865  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-06  0.020659  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "...              ...       ...    ...    ...    ...    ...       ...    ...   \n",
      "2025-03-25  0.022877  0.022877    0.0    0.0    0.0    0.0  0.022877    0.0   \n",
      "2025-03-26  0.022851  0.022851    0.0    0.0    0.0    0.0  0.022851    0.0   \n",
      "2025-03-27  0.022849  0.022849    0.0    0.0    0.0    0.0  0.022849    0.0   \n",
      "2025-03-28  0.022837  0.022837    0.0    0.0    0.0    0.0  0.022837    0.0   \n",
      "2025-03-31  0.022821  0.022821    0.0    0.0    0.0    0.0  0.022821    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data                      ...                                                \n",
      "2019-09-02    0.0    0.0  ...  0.020947    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0  ...  0.020953    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0  ...  0.020938    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0  ...  0.020865    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0  ...  0.020659    0.0    0.0    0.0    0.0    0.0   \n",
      "...           ...    ...  ...       ...    ...    ...    ...    ...    ...   \n",
      "2025-03-25    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-26    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-27    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-28    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-31    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  Soma_verificacao  \n",
      "Data                                               \n",
      "2019-09-02    0.0    0.0    0.0               1.0  \n",
      "2019-09-03    0.0    0.0    0.0               1.0  \n",
      "2019-09-04    0.0    0.0    0.0               1.0  \n",
      "2019-09-05    0.0    0.0    0.0               1.0  \n",
      "2019-09-06    0.0    0.0    0.0               1.0  \n",
      "...           ...    ...    ...               ...  \n",
      "2025-03-25    0.0    0.0    0.0               1.0  \n",
      "2025-03-26    0.0    0.0    0.0               1.0  \n",
      "2025-03-27    0.0    0.0    0.0               1.0  \n",
      "2025-03-28    0.0    0.0    0.0               1.0  \n",
      "2025-03-31    0.0    0.0    0.0               1.0  \n",
      "\n",
      "[1456 rows x 172 columns]\n",
      "\n",
      "Resultado do df_long_indices_smal:\n",
      "               TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.033645  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-03  0.033563  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-04  0.033692  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-05  0.033625  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-06  0.033571  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "...              ...       ...    ...    ...    ...    ...       ...    ...   \n",
      "2025-03-25  0.025404  0.024392    0.0    0.0    0.0    0.0  0.025355    0.0   \n",
      "2025-03-26  0.025274  0.024393    0.0    0.0    0.0    0.0  0.025458    0.0   \n",
      "2025-03-27  0.025297  0.024439    0.0    0.0    0.0    0.0  0.025564    0.0   \n",
      "2025-03-28  0.025328  0.024010    0.0    0.0    0.0    0.0  0.025512    0.0   \n",
      "2025-03-31  0.025422  0.023881    0.0    0.0    0.0    0.0  0.025426    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data                      ...                                                \n",
      "2019-09-02    0.0    0.0  ...  0.045386    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0  ...  0.045317    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0  ...  0.045655    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0  ...  0.045774    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0  ...  0.045842    0.0    0.0    0.0    0.0    0.0   \n",
      "...           ...    ...  ...       ...    ...    ...    ...    ...    ...   \n",
      "2025-03-25    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-26    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-27    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-28    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-31    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  Soma_verificacao  \n",
      "Data                                               \n",
      "2019-09-02    0.0    0.0    0.0               1.0  \n",
      "2019-09-03    0.0    0.0    0.0               1.0  \n",
      "2019-09-04    0.0    0.0    0.0               1.0  \n",
      "2019-09-05    0.0    0.0    0.0               1.0  \n",
      "2019-09-06    0.0    0.0    0.0               1.0  \n",
      "...           ...    ...    ...               ...  \n",
      "2025-03-25    0.0    0.0    0.0               1.0  \n",
      "2025-03-26    0.0    0.0    0.0               1.0  \n",
      "2025-03-27    0.0    0.0    0.0               1.0  \n",
      "2025-03-28    0.0    0.0    0.0               1.0  \n",
      "2025-03-31    0.0    0.0    0.0               1.0  \n",
      "\n",
      "[1456 rows x 172 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Verificações iniciais\n",
    "# ---------------------------\n",
    "\n",
    "# Checa se os DataFrames necessários existem\n",
    "if 'df_port_comp' not in globals():\n",
    "    raise Exception(\"A variável 'df_port_comp' não foi definida.\")\n",
    "if 'df_peso_port_ibov' not in globals():\n",
    "    raise Exception(\"A variável 'df_peso_port_ibov' não foi definida.\")\n",
    "if 'df_peso_port_smal' not in globals():\n",
    "    raise Exception(\"A variável 'df_peso_port_smal' não foi definida.\")\n",
    "\n",
    "# Converte os índices para datetime se necessário (para correto alinhamento)\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_port_comp.index):\n",
    "    df_port_comp.index = pd.to_datetime(df_port_comp.index)\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_peso_port_ibov.index):\n",
    "    df_peso_port_ibov.index = pd.to_datetime(df_peso_port_ibov.index)\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_peso_port_smal.index):\n",
    "    df_peso_port_smal.index = pd.to_datetime(df_peso_port_smal.index)\n",
    "\n",
    "# ---------------------------\n",
    "# Cálculos para IBOV\n",
    "# ---------------------------\n",
    "\n",
    "# Verifica se a coluna total para IBOV está presente\n",
    "if 'Total_Ibov_%' not in df_peso_port_ibov.columns:\n",
    "    raise Exception(\"A coluna 'Total_Ibov_%' não foi encontrada em df_peso_port_ibov.\")\n",
    "\n",
    "# Define as datas comuns entre df_port_comp e df_peso_port_ibov\n",
    "common_dates_ibov = df_port_comp.index.intersection(df_peso_port_ibov.index)\n",
    "if common_dates_ibov.empty:\n",
    "    raise Exception(\"Não foram encontradas datas comuns para IBOV.\")\n",
    "\n",
    "# Define as colunas dos papéis: interseção entre as colunas de df_port_comp e de df_peso_port_ibov (excluindo 'Total_Ibov_%')\n",
    "paper_cols_ibov = df_peso_port_ibov.columns.difference(['Total_Ibov_%'])\n",
    "common_cols_ibov = df_port_comp.columns.intersection(paper_cols_ibov)\n",
    "if common_cols_ibov.empty:\n",
    "    raise Exception(\"Não foram encontradas colunas comuns (papéis) para IBOV.\")\n",
    "\n",
    "# Seleciona os DataFrames para os papéis e datas comuns (fazendo cópia para segurança)\n",
    "df_port_comp_ibov = df_port_comp.loc[common_dates_ibov, common_cols_ibov].copy()\n",
    "df_peso_ibov = df_peso_port_ibov.loc[common_dates_ibov, common_cols_ibov].copy()\n",
    "\n",
    "# Converte os dados para numérico, caso haja formatações (usando errors='coerce' para transformar problemas em NaN)\n",
    "df_port_comp_ibov = df_port_comp_ibov.apply(pd.to_numeric, errors='coerce')\n",
    "df_peso_ibov = df_peso_ibov.apply(pd.to_numeric, errors='coerce')\n",
    "total_ibov = pd.to_numeric(df_peso_port_ibov.loc[common_dates_ibov, 'Total_Ibov_%'], errors='coerce')\n",
    "\n",
    "# Calcula 'n' para cada data como a soma dos valores do df_port_comp_ibov \n",
    "n_series_ibov = df_port_comp_ibov.sum(axis=1).replace(0, pd.NA)\n",
    "\n",
    "# Aplica a fórmula para IBOV:\n",
    "# ((1 - Total_Ibov_%)/n + Peso Port IBOVx) * Port Comp\n",
    "componente_comum_ibov = (1 - total_ibov).div(n_series_ibov, axis=0)\n",
    "df_long_indices_ibov = (df_peso_ibov.add(componente_comum_ibov, axis=0)) * df_port_comp_ibov\n",
    "\n",
    "# Adiciona coluna de verificação (soma das colunas por data)\n",
    "df_long_indices_ibov = df_long_indices_ibov.assign(Soma_verificacao = df_long_indices_ibov.sum(axis=1))\n",
    "\n",
    "# ---------------------------\n",
    "# Cálculos para SMAL\n",
    "# ---------------------------\n",
    "\n",
    "# Verifica se a coluna total para SMAL está presente\n",
    "if 'Total_Smal_%' not in df_peso_port_smal.columns:\n",
    "    raise Exception(\"A coluna 'Total_Smal_%' não foi encontrada em df_peso_port_smal.\")\n",
    "\n",
    "# Define as datas comuns entre df_port_comp e df_peso_port_smal\n",
    "common_dates_smal = df_port_comp.index.intersection(df_peso_port_smal.index)\n",
    "if common_dates_smal.empty:\n",
    "    raise Exception(\"Não foram encontradas datas comuns para SMAL.\")\n",
    "\n",
    "# Define as colunas dos papéis para SMAL (excluindo 'Total_Smal_%')\n",
    "paper_cols_smal = df_peso_port_smal.columns.difference(['Total_Smal_%'])\n",
    "common_cols_smal = df_port_comp.columns.intersection(paper_cols_smal)\n",
    "if common_cols_smal.empty:\n",
    "    raise Exception(\"Não foram encontradas colunas comuns (papéis) para SMAL.\")\n",
    "\n",
    "# Seleciona os DataFrames para os papéis e datas comuns para SMAL\n",
    "df_port_comp_smal = df_port_comp.loc[common_dates_smal, common_cols_smal].copy()\n",
    "df_peso_smal = df_peso_port_smal.loc[common_dates_smal, common_cols_smal].copy()\n",
    "\n",
    "# Converte os dados para numérico\n",
    "df_port_comp_smal = df_port_comp_smal.apply(pd.to_numeric, errors='coerce')\n",
    "df_peso_smal = df_peso_smal.apply(pd.to_numeric, errors='coerce')\n",
    "total_smal = pd.to_numeric(df_peso_port_smal.loc[common_dates_smal, 'Total_Smal_%'], errors='coerce')\n",
    "\n",
    "# Calcula 'n' para SMAL como a soma dos valores dos papéis por data\n",
    "n_series_smal = df_port_comp_smal.sum(axis=1).replace(0, pd.NA)\n",
    "\n",
    "# Aplica a fórmula para SMAL:\n",
    "# ((1 - Total_Smal_%)/n + Peso Port SMALx) * Port Comp\n",
    "componente_comum_smal = (1 - total_smal).div(n_series_smal, axis=0)\n",
    "df_long_indices_smal = (df_peso_smal.add(componente_comum_smal, axis=0)) * df_port_comp_smal\n",
    "\n",
    "# Adiciona coluna de verificação (soma dos valores por data)\n",
    "df_long_indices_smal = df_long_indices_smal.assign(Soma_verificacao = df_long_indices_smal.sum(axis=1))\n",
    "\n",
    "# ---------------------------\n",
    "# Exibe os resultados\n",
    "# ---------------------------\n",
    "\n",
    "print(\"Resultado do df_long_indices_ibov:\")\n",
    "print(df_long_indices_ibov)\n",
    "\n",
    "print(\"\\nResultado do df_long_indices_smal:\")\n",
    "print(df_long_indices_smal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1340c171",
   "metadata": {},
   "source": [
    "Peso Combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5e6f83db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do DataFrame 'df_peso_combinado':\n",
      "               TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                           \n",
      "2019-09-02  0.004461    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03  0.004410    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04  0.004467    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05  0.004347    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06  0.004290    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            GGPS3  ...  UNIP6  ORVR3  AMBP3  CVCB3  TASA4  GOLL4  EMBR3  \\\n",
      "Data               ...                                                    \n",
      "2019-09-02    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            combinado  Peso IBOV  Peso SMAL  \n",
      "Data                                         \n",
      "2019-09-02   0.696600   0.653715   0.346285  \n",
      "2019-09-03   0.697249   0.652880   0.347120  \n",
      "2019-09-04   0.695749   0.654855   0.345145  \n",
      "2019-09-05   0.696306   0.657068   0.342932  \n",
      "2019-09-06   0.701560   0.659751   0.340249  \n",
      "\n",
      "[5 rows x 174 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MiguelMachado\\AppData\\Local\\Temp\\ipykernel_25420\\210274023.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_peso_combinado['combinado'] = df_peso_combinado[tickers].sum(axis=1)\n",
      "C:\\Users\\MiguelMachado\\AppData\\Local\\Temp\\ipykernel_25420\\210274023.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_peso_combinado['Peso IBOV'] = total_ibov.div(df_peso_combinado['combinado'])\n",
      "C:\\Users\\MiguelMachado\\AppData\\Local\\Temp\\ipykernel_25420\\210274023.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_peso_combinado['Peso SMAL'] = total_smal.div(df_peso_combinado['combinado'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Definição da lista de tickers (ajuste conforme necessário) ---\n",
    "tickers = [\n",
    "    'TGMA3', 'ARML3', 'VAMO3', 'ALPA4', 'AZZA3', 'ASAI3', 'CEAB3', 'CRFB3', \n",
    "    'ESPA3', 'GGPS3', 'GMAT3', 'GRND3', 'GUAR3', 'LJQQ3', 'LREN3', 'MGLU3', \n",
    "    'NTCO3', 'PETZ3', 'PNVL3', 'RADL3', 'SBFG3', 'SMFT3', 'VIVA3', 'VULC3', \n",
    "    'DXCO3', 'FRAS3', 'INTB3', 'LEVE3', 'MILS3', 'MYPK3', 'POMO4', 'PRNR3', \n",
    "    'PTBL3', 'RAPT4', 'TUPY3', 'WEGE3', 'CBAV3', 'CMIN3', 'CSNA3', 'GGBR4', \n",
    "    'KLBN11', 'RANI3', 'SUZB3', 'USIM5', 'VALE3', 'ALOS3', 'CURY3', 'CYRE3', \n",
    "    'DIRR3', 'EZTC3', 'IGTI11', 'JHSF3', 'MRVE3', 'MULT3', 'PLPL3', 'TEND3', \n",
    "    'BMOB3', 'LWSA3', 'NGRD3', 'POSI3', 'TOTS3', 'VLID3', 'HYPE3', 'BRIT3', \n",
    "    'DESK3', 'FIQE3', 'TIMS3', 'VIVT3', 'MOVI3', 'RENT3', 'RAIZ4', 'UGPA3', \n",
    "    'VBBR3', 'ENAT3', 'OPCT3', 'PETR4', 'PRIO3', 'RECV3', 'BRAV3', 'CCRO3', \n",
    "    'ECOR3', 'HBSA3', 'PORT3', 'RAIL3', 'STBP3', 'AESB3', 'AURE3', 'CMIG4', \n",
    "    'CPFE3', 'CPLE6', 'CSMG3', 'EGIE3', 'ELET6', 'ENEV3', 'ENGI11', 'EQTL3', \n",
    "    'NEOE3', 'SAPR11', 'SBSP3', 'SRNA3', 'ISAE4', 'ABCB4', 'B3SA3', 'BBAS3', \n",
    "    'BBDC4', 'BBSE3', 'BPAC11', 'BRBI11', 'CSUD3', 'CXSE3', 'IRBR3', 'ITUB4', \n",
    "    'QUAL3', 'PSSA3', 'SANB11', 'WIZC3', 'ABEV3', 'ZAMP3', 'BEEF3', 'BRFS3', \n",
    "    'CAML3', 'JBSS3', 'MDIA3', 'MRFG3', 'JALL3', 'KEPL3', 'SLCE3', 'SMTO3', \n",
    "    'SOJA3', 'TTEN3', 'ANIM3', 'COGN3', 'YDUQ3', 'FLRY3', 'HAPV3', 'ODPV3', \n",
    "    'ONCO3', 'RDOR3', 'XPBR31', 'MLAS3', 'CIEL3', 'SOMA3', 'BPAN4', 'BRSR6', \n",
    "    'LOGG3', 'EVEN3', 'MDNE3', 'LAVV3', 'DASA3', 'MATD3', 'VVEO3', 'CLSA3', \n",
    "    'CASH3', 'TRIS3', 'BLAU3', 'GFSA3', 'MTRE3', 'IFCM3', 'MBLY3', 'AMAR3', \n",
    "    'BRML3', 'TAEE11', 'ALUP11', 'AZUL4', 'UNIP6', 'ORVR3', 'AMBP3', 'CVCB3', \n",
    "    'TASA4', 'GOLL4', 'EMBR3'\n",
    "]\n",
    "\n",
    "# --- Alinhamento de datas ---\n",
    "# Define as datas comuns entre df_peso_port_ibov e df_peso_port_smal\n",
    "common_dates = df_peso_port_ibov.index.intersection(df_peso_port_smal.index)\n",
    "if common_dates.empty:\n",
    "    raise Exception(\"Não foram encontradas datas comuns entre df_peso_port_ibov e df_peso_port_smal.\")\n",
    "\n",
    "# --- Subconjunto dos tickers para cada DataFrame ---\n",
    "# Seleciona as colunas dos tickers dos dois DataFrames para as datas comuns\n",
    "df_ibov_tickers = df_peso_port_ibov.loc[common_dates, tickers].copy()\n",
    "df_smal_tickers = df_peso_port_smal.loc[common_dates, tickers].copy()\n",
    "\n",
    "# Converte para numérico, se necessário\n",
    "df_ibov_tickers = df_ibov_tickers.apply(pd.to_numeric, errors='coerce')\n",
    "df_smal_tickers = df_smal_tickers.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# --- Cálculo do df_peso_combinado ---\n",
    "# Soma os valores dos tickers de SMAL e de IBOV\n",
    "df_peso_combinado = df_ibov_tickers.add(df_smal_tickers, fill_value=0)\n",
    "\n",
    "# Cria a coluna \"combinado\" com a soma, linha a linha, dos valores dos tickers\n",
    "df_peso_combinado['combinado'] = df_peso_combinado[tickers].sum(axis=1)\n",
    "\n",
    "# --- Criação das colunas \"Peso IBOV\" e \"Peso SMAL\" ---\n",
    "# Converte os valores dos totais para numérico\n",
    "total_ibov = pd.to_numeric(df_peso_port_ibov.loc[common_dates, 'Total_Ibov_%'], errors='coerce')\n",
    "total_smal = pd.to_numeric(df_peso_port_smal.loc[common_dates, 'Total_Smal_%'], errors='coerce')\n",
    "\n",
    "# Cria a coluna \"Peso IBOV\": razão entre Total_Ibov_% e a coluna \"combinado\"\n",
    "df_peso_combinado['Peso IBOV'] = total_ibov.div(df_peso_combinado['combinado'])\n",
    "\n",
    "# Cria a coluna \"Peso SMAL\": razão entre Total_Smal_% e a coluna \"combinado\"\n",
    "df_peso_combinado['Peso SMAL'] = total_smal.div(df_peso_combinado['combinado'])\n",
    "\n",
    "# --- Exibe o resultado ---\n",
    "print(\"Resultado do DataFrame 'df_peso_combinado':\")\n",
    "print(df_peso_combinado.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373f5eb",
   "metadata": {},
   "source": [
    "Short Passivo IBOV e SMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "08c567c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_alvancagem_short_passivo_ibov:\n",
      "            alvancagem_short_passivo_ibov\n",
      "Data                                     \n",
      "2019-09-02                       1.836136\n",
      "2019-09-03                       1.835603\n",
      "2019-09-04                       1.836934\n",
      "2019-09-05                       1.843388\n",
      "2019-09-06                       1.861694\n",
      "\n",
      "Resultado do df_alvancagem_short_passivo_smal:\n",
      "            alvancagem_short_passivo_smal\n",
      "Data                                     \n",
      "2019-09-02                       1.317908\n",
      "2019-09-03                       1.319312\n",
      "2019-09-04                       1.316022\n",
      "2019-09-05                       1.313690\n",
      "2019-09-06                       1.313551\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Para IBOV ---\n",
    "# Verifica se a coluna 'Total_Ibov_%' está presente em df_peso_port_ibov\n",
    "if 'Total_Ibov_%' not in df_peso_port_ibov.columns:\n",
    "    raise Exception(\"A coluna 'Total_Ibov_%' não foi encontrada em df_peso_port_ibov.\")\n",
    "\n",
    "# Converte os valores da coluna para numérico (caso haja problemas de formatação)\n",
    "total_ibov = pd.to_numeric(df_peso_port_ibov['Total_Ibov_%'], errors='coerce')\n",
    "\n",
    "# Calcula a alavancagem de short passivo para IBOV: 1 / (1 - Total_Ibov_%)\n",
    "df_alvancagem_short_passivo_ibov = pd.DataFrame(1 / (1 - total_ibov), index=df_peso_port_ibov.index)\n",
    "df_alvancagem_short_passivo_ibov.columns = ['alvancagem_short_passivo_ibov']\n",
    "\n",
    "# Exibe o resultado para IBOV\n",
    "print(\"Resultado do df_alvancagem_short_passivo_ibov:\")\n",
    "print(df_alvancagem_short_passivo_ibov.head())\n",
    "\n",
    "# --- Para SMAL ---\n",
    "# Verifica se a coluna 'Total_Smal_%' está presente em df_peso_port_smal\n",
    "if 'Total_Smal_%' not in df_peso_port_smal.columns:\n",
    "    raise Exception(\"A coluna 'Total_Smal_%' não foi encontrada em df_peso_port_smal.\")\n",
    "\n",
    "# Converte os valores da coluna para numérico\n",
    "total_smal = pd.to_numeric(df_peso_port_smal['Total_Smal_%'], errors='coerce')\n",
    "\n",
    "# Calcula a alavancagem de short passivo para SMAL: 1 / (1 - Total_Smal_%)\n",
    "df_alvancagem_short_passivo_smal = pd.DataFrame(1 / (1 - total_smal), index=df_peso_port_smal.index)\n",
    "df_alvancagem_short_passivo_smal.columns = ['alvancagem_short_passivo_smal']\n",
    "\n",
    "# Exibe o resultado para SMAL\n",
    "print(\"\\nResultado do df_alvancagem_short_passivo_smal:\")\n",
    "print(df_alvancagem_short_passivo_smal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c1bfbe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_prod_short_passivo_ibov:\n",
      "            prod_short_passivo_ibov\n",
      "Data                               \n",
      "2019-09-02                 1.200310\n",
      "2019-09-03                 1.198429\n",
      "2019-09-04                 1.202926\n",
      "2019-09-05                 1.211232\n",
      "2019-09-06                 1.228254\n",
      "\n",
      "Resultado do df_prod_short_passivo_smal:\n",
      "            prod_short_passivo_smal\n",
      "Data                               \n",
      "2019-09-02                 0.456371\n",
      "2019-09-03                 0.457959\n",
      "2019-09-04                 0.454218\n",
      "2019-09-05                 0.450506\n",
      "2019-09-06                 0.446935\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Verificações e cálculo para IBOV ---\n",
    "if 'df_alvancagem_short_passivo_ibov' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_alvancagem_short_passivo_ibov' não foi definido.\")\n",
    "if 'df_peso_combinado' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_combinado' não foi definido.\")\n",
    "if 'Peso IBOV' not in df_peso_combinado.columns:\n",
    "    raise Exception(\"A coluna 'Peso IBOV' não foi encontrada em df_peso_combinado.\")\n",
    "\n",
    "# Multiplica a alavancagem de short passivo do IBOV pelo Peso IBOV\n",
    "prod_short_ibov = df_alvancagem_short_passivo_ibov['alvancagem_short_passivo_ibov'] * df_peso_combinado['Peso IBOV']\n",
    "df_prod_short_passivo_ibov = pd.DataFrame(prod_short_ibov, index=df_alvancagem_short_passivo_ibov.index)\n",
    "df_prod_short_passivo_ibov.columns = ['prod_short_passivo_ibov']\n",
    "\n",
    "# --- Verificações e cálculo para SMAL ---\n",
    "if 'df_alvancagem_short_passivo_smal' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_alvancagem_short_passivo_smal' não foi definido.\")\n",
    "if 'Peso SMAL' not in df_peso_combinado.columns:\n",
    "    raise Exception(\"A coluna 'Peso SMAL' não foi encontrada em df_peso_combinado.\")\n",
    "\n",
    "# Multiplica a alavancagem de short passivo do SMAL pelo Peso SMAL\n",
    "prod_short_smal = df_alvancagem_short_passivo_smal['alvancagem_short_passivo_smal'] * df_peso_combinado['Peso SMAL']\n",
    "df_prod_short_passivo_smal = pd.DataFrame(prod_short_smal, index=df_alvancagem_short_passivo_smal.index)\n",
    "df_prod_short_passivo_smal.columns = ['prod_short_passivo_smal']\n",
    "\n",
    "# --- Exibe os resultados ---\n",
    "print(\"Resultado do df_prod_short_passivo_ibov:\")\n",
    "print(df_prod_short_passivo_ibov.head())\n",
    "\n",
    "print(\"\\nResultado do df_prod_short_passivo_smal:\")\n",
    "print(df_prod_short_passivo_smal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "dc557974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_short_passivo_ibov:\n",
      "            TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                        \n",
      "2019-09-02    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            GGPS3  ...    TAEE11  ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data               ...                                                        \n",
      "2019-09-02    0.0  ...  0.004220     0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0  ...  0.004256     0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0  ...  0.004283     0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0  ...  0.004254     0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0  ...  0.004279     0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  \n",
      "Data                             \n",
      "2019-09-02    0.0    0.0    0.0  \n",
      "2019-09-03    0.0    0.0    0.0  \n",
      "2019-09-04    0.0    0.0    0.0  \n",
      "2019-09-05    0.0    0.0    0.0  \n",
      "2019-09-06    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n",
      "\n",
      "Resultado do df_short_passivo_smal:\n",
      "               TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                           \n",
      "2019-09-02  0.002036    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03  0.002020    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04  0.002029    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05  0.001958    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06  0.001917    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            GGPS3  ...    TAEE11    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data               ...                                                          \n",
      "2019-09-02    0.0  ...  0.011651  0.007394    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0  ...  0.011838  0.007403    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0  ...  0.011972  0.007463    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0  ...  0.011780  0.007432    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0  ...  0.011744  0.007402    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  \n",
      "Data                             \n",
      "2019-09-02    0.0    0.0    0.0  \n",
      "2019-09-03    0.0    0.0    0.0  \n",
      "2019-09-04    0.0    0.0    0.0  \n",
      "2019-09-05    0.0    0.0    0.0  \n",
      "2019-09-06    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ============================\n",
    "# Para IBOV\n",
    "# ============================\n",
    "# Verifica se as variáveis necessárias estão definidas\n",
    "if 'df_prod_short_passivo_ibov' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_prod_short_passivo_ibov' não foi definido.\")\n",
    "if 'df_peso_port_ibov' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_port_ibov' não foi definido.\")\n",
    "if 'tickers' not in globals():\n",
    "    raise Exception(\"A lista de tickers não foi definida.\")\n",
    "\n",
    "# Seleciona do df_peso_port_ibov apenas as colunas correspondentes aos tickers, para as datas (índices) de df_prod_short_passivo_ibov\n",
    "df_peso_ibov_tickers = df_peso_port_ibov.loc[df_prod_short_passivo_ibov.index, tickers].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Realiza a multiplicação: multiplica, linha a linha, o valor da série 'prod_short_passivo_ibov'\n",
    "# pelos valores correspondentes dos tickers\n",
    "df_short_passivo_ibov = df_peso_ibov_tickers.mul(df_prod_short_passivo_ibov['prod_short_passivo_ibov'], axis=0)\n",
    "\n",
    "# Exibe o resultado para IBOV\n",
    "print(\"Resultado do df_short_passivo_ibov:\")\n",
    "print(df_short_passivo_ibov.head())\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Para SMAL\n",
    "# ============================\n",
    "# Verifica se as variáveis necessárias estão definidas\n",
    "if 'df_prod_short_passivo_smal' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_prod_short_passivo_smal' não foi definido.\")\n",
    "if 'df_peso_port_smal' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_port_smal' não foi definido.\")\n",
    "\n",
    "# Seleciona do df_peso_port_smal apenas as colunas correspondentes aos tickers, para as datas (índices) de df_prod_short_passivo_smal\n",
    "df_peso_smal_tickers = df_peso_port_smal.loc[df_prod_short_passivo_smal.index, tickers].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Multiplica, linha a linha, o valor da série 'prod_short_passivo_smal'\n",
    "# pelos valores correspondentes dos tickers\n",
    "df_short_passivo_smal = df_peso_smal_tickers.mul(df_prod_short_passivo_smal['prod_short_passivo_smal'], axis=0)\n",
    "\n",
    "# Exibe o resultado para SMAL\n",
    "print(\"\\nResultado do df_short_passivo_smal:\")\n",
    "print(df_short_passivo_smal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cb077ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_soma_short_passivo_ibov:\n",
      "            soma_short_passivo_ibov\n",
      "Data                               \n",
      "2019-09-02                 0.546595\n",
      "2019-09-03                 0.545548\n",
      "2019-09-04                 0.548071\n",
      "2019-09-05                 0.554163\n",
      "2019-09-06                 0.568503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica se o DataFrame df_short_passivo_ibov existe\n",
    "if 'df_short_passivo_ibov' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_short_passivo_ibov' não foi definido.\")\n",
    "\n",
    "# Calcula a soma das linhas (axis=1) do df_short_passivo_ibov\n",
    "# e cria um novo DataFrame com esta soma\n",
    "df_soma_short_passivo_ibov = pd.DataFrame(df_short_passivo_ibov.sum(axis=1), \n",
    "                                           columns=['soma_short_passivo_ibov'])\n",
    "\n",
    "# Exibe os primeiros registros do DataFrame resultante\n",
    "print(\"Resultado do df_soma_short_passivo_ibov:\")\n",
    "print(df_soma_short_passivo_ibov.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97532386",
   "metadata": {},
   "source": [
    "Peso Port Hib Adj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8f559245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_peso_port_hib_adj:\n",
      "               TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                           \n",
      "2019-09-02  0.040498    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03  0.040481    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04  0.040490    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05  0.040420    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06  0.040379    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            GGPS3  ...    TAEE11    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data               ...                                                          \n",
      "2019-09-02    0.0  ...  0.054332  0.045856    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0  ...  0.054556  0.045864    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0  ...  0.054717  0.045924    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0  ...  0.054496  0.045893    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0  ...  0.054484  0.045864    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  \n",
      "Data                             \n",
      "2019-09-02    0.0    0.0    0.0  \n",
      "2019-09-03    0.0    0.0    0.0  \n",
      "2019-09-04    0.0    0.0    0.0  \n",
      "2019-09-05    0.0    0.0    0.0  \n",
      "2019-09-06    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Verificações iniciais ---\n",
    "if 'df_port_comp' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_port_comp' não foi definido.\")\n",
    "if 'df_short_passivo_ibov' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_short_passivo_ibov' não foi definido.\")\n",
    "if 'df_short_passivo_smal' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_short_passivo_smal' não foi definido.\")\n",
    "if 'tickers' not in globals():\n",
    "    raise Exception(\"A lista de tickers não foi definida.\")\n",
    "\n",
    "# --- Seleção dos dados para as empresas (tickers) ---\n",
    "# Filtra as colunas de df_port_comp para conter apenas os tickers\n",
    "df_port_comp_tickers = df_port_comp[tickers].copy()\n",
    "\n",
    "# Calcula n para cada data como a soma dos valores dos tickers\n",
    "n_series = df_port_comp_tickers.sum(axis=1)\n",
    "\n",
    "# Calcula o termo (100%/n), considerando 100% como 1\n",
    "term_div = 1 / n_series\n",
    "\n",
    "# --- Preparação dos fatores de ajuste ---\n",
    "# Vamos garantir que os DataFrames de short passivo estejam restritos aos tickers.\n",
    "# Supondo que df_short_passivo_ibov e df_short_passivo_smal tenham, ou possuam colunas compatíveis com os tickers,\n",
    "# selecionamos apenas essas colunas:\n",
    "df_short_passivo_ibov_sub = df_short_passivo_ibov[tickers].copy()\n",
    "df_short_passivo_smal_sub = df_short_passivo_smal[tickers].copy()\n",
    "\n",
    "# Agora, somamos os DataFrames de short passivo e adicionamos o termo 1/n (que será adicionado a todas as colunas de cada linha)\n",
    "# Usamos .add com axis=0 para que o termo (uma Series) seja somado a cada coluna da linha correspondente.\n",
    "adj_factor = df_short_passivo_ibov_sub.add(df_short_passivo_smal_sub, axis=0).add(term_div, axis=0)\n",
    "\n",
    "# --- Cálculo final ---\n",
    "# Multiplica o fator ajustado pelo df_port_comp somente para os tickers\n",
    "df_peso_port_hib_adj = adj_factor * df_port_comp_tickers\n",
    "\n",
    "# --- Exibe o resultado ---\n",
    "print(\"Resultado do df_peso_port_hib_adj:\")\n",
    "print(df_peso_port_hib_adj.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b5f7bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_gross_long:\n",
      "            gross_long\n",
      "Data                  \n",
      "2019-09-02    1.656682\n",
      "2019-09-03    1.656388\n",
      "2019-09-04    1.657144\n",
      "2019-09-05    1.661738\n",
      "2019-09-06    1.675189\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica se o DataFrame df_peso_port_hib_adj está definido\n",
    "if 'df_peso_port_hib_adj' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_port_hib_adj' não foi definido.\")\n",
    "\n",
    "# Calcula a soma de cada linha do df_peso_port_hib_adj (soma dos valores dos tickers)\n",
    "df_gross_long = pd.DataFrame(df_peso_port_hib_adj.sum(axis=1), columns=['gross_long'])\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame resultante\n",
    "print(\"Resultado do df_gross_long:\")\n",
    "print(df_gross_long.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dab15f",
   "metadata": {},
   "source": [
    "Peso Port Hib Adj. Limitado 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "69d0ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_redutor:\n",
      "             redutor\n",
      "Data                \n",
      "2019-09-02  0.025257\n",
      "2019-09-03  0.025246\n",
      "2019-09-04  0.025275\n",
      "2019-09-05  0.025451\n",
      "2019-09-06  0.025969\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Verifica se os DataFrames necessários existem\n",
    "if 'df_gross_long' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_gross_long' não foi definido.\")\n",
    "if 'df_port_comp' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_port_comp' não foi definido.\")\n",
    "if 'tickers' not in globals():\n",
    "    raise Exception(\"A lista de tickers não foi definida.\")\n",
    "\n",
    "# Calcula n: soma de cada linha dos tickers no df_port_comp\n",
    "df_port_comp_tickers = df_port_comp[tickers].copy()\n",
    "n_series = df_port_comp_tickers.sum(axis=1)\n",
    "\n",
    "# Calcula o fator: (df_gross_long - 1) / n_series\n",
    "# df_gross_long possui uma coluna chamada 'gross_long'\n",
    "fator = (df_gross_long['gross_long'] - 1) / n_series\n",
    "\n",
    "# Garante que o valor final seja não negativo, utilizando np.maximum\n",
    "valores_redutor = np.maximum(fator, 0)\n",
    "\n",
    "# Cria o DataFrame df_redutor com os valores calculados\n",
    "df_redutor = pd.DataFrame(valores_redutor, index=df_gross_long.index, columns=['redutor'])\n",
    "\n",
    "# Exibe os primeiros resultados\n",
    "\n",
    "print(\"Resultado do df_redutor:\")\n",
    "print(df_redutor.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "75ddeae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_peso_port_hib_adj_limitado_100:\n",
      "               TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                           \n",
      "2019-09-02  0.015241   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-03  0.015235   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-04  0.015216   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-05  0.014968   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-06  0.014410   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "\n",
      "            GGPS3  ...    TAEE11    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data               ...                                                          \n",
      "2019-09-02   -0.0  ...  0.029075  0.020599   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-03   -0.0  ...  0.029311  0.020619   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-04   -0.0  ...  0.029442  0.020649   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-05   -0.0  ...  0.029044  0.020442   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "2019-09-06   -0.0  ...  0.028515  0.019895   -0.0   -0.0   -0.0   -0.0   -0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  \n",
      "Data                             \n",
      "2019-09-02   -0.0   -0.0   -0.0  \n",
      "2019-09-03   -0.0   -0.0   -0.0  \n",
      "2019-09-04   -0.0   -0.0   -0.0  \n",
      "2019-09-05   -0.0   -0.0   -0.0  \n",
      "2019-09-06   -0.0   -0.0   -0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica se os DataFrames e a lista de tickers estão definidos\n",
    "if 'df_peso_port_hib_adj' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_port_hib_adj' não foi definido.\")\n",
    "if 'df_redutor' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_redutor' não foi definido.\")\n",
    "if 'df_port_comp' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_port_comp' não foi definido.\")\n",
    "if 'tickers' not in globals():\n",
    "    raise Exception(\"A lista de tickers não foi definida.\")\n",
    "\n",
    "# Filtra df_port_comp para considerar apenas as empresas (tickers)\n",
    "df_port_comp_tickers = df_port_comp[tickers].copy()\n",
    "\n",
    "# Subtrai, para cada linha (data), o valor contido em df_redutor (coluna \"redutor\")\n",
    "# de cada valor do df_peso_port_hib_adj. Note que o broadcasting é feito pela correspondência de índices.\n",
    "df_ajustado = df_peso_port_hib_adj.subtract(df_redutor['redutor'], axis=0)\n",
    "\n",
    "# Multiplica o DataFrame ajustado pelo df_port_comp restrito às colunas de tickers\n",
    "df_peso_port_hib_adj_limitado_100 = df_ajustado * df_port_comp_tickers\n",
    "\n",
    "# Exibe as primeiras linhas do resultado\n",
    "print(\"Resultado do df_peso_port_hib_adj_limitado_100:\")\n",
    "print(df_peso_port_hib_adj_limitado_100.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "74b21694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_gross_long_novo:\n",
      "            gross_long_novo\n",
      "Data                       \n",
      "2019-09-02              1.0\n",
      "2019-09-03              1.0\n",
      "2019-09-04              1.0\n",
      "2019-09-05              1.0\n",
      "2019-09-06              1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica se o DataFrame df_peso_port_hib_adj_limitado_100 está definido\n",
    "if 'df_peso_port_hib_adj_limitado_100' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_port_hib_adj_limitado_100' não foi definido.\")\n",
    "\n",
    "# Calcula a soma de cada linha (axis=1) e cria o DataFrame df_gross_long_novo\n",
    "df_gross_long_novo = pd.DataFrame(df_peso_port_hib_adj_limitado_100.sum(axis=1), \n",
    "                                  columns=['gross_long_novo'])\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame resultante\n",
    "print(\"Resultado do df_gross_long_novo:\")\n",
    "print(df_gross_long_novo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0515e4",
   "metadata": {},
   "source": [
    "Peso Long Single Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b9566dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_peso_long_single_names:\n",
      "               TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                           \n",
      "2019-09-02  0.038462    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03  0.038462    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04  0.038462    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05  0.038462    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06  0.038462    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            GGPS3  ...    TAEE11    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data               ...                                                          \n",
      "2019-09-02    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  \n",
      "Data                             \n",
      "2019-09-02    0.0    0.0    0.0  \n",
      "2019-09-03    0.0    0.0    0.0  \n",
      "2019-09-04    0.0    0.0    0.0  \n",
      "2019-09-05    0.0    0.0    0.0  \n",
      "2019-09-06    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica se os DataFrames e a lista de tickers estão definidos\n",
    "if 'df_port_comp' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_port_comp' não foi definido.\")\n",
    "if 'tickers' not in globals():\n",
    "    raise Exception(\"A lista de tickers não foi definida.\")\n",
    "\n",
    "# Seleciona apenas as colunas dos tickers em df_port_comp\n",
    "df_port_comp_tickers = df_port_comp[tickers].copy()\n",
    "\n",
    "# Calcula n como a soma de cada linha (para os tickers)\n",
    "n_series = df_port_comp_tickers.sum(axis=1)\n",
    "\n",
    "# Aplica a fórmula 1/n * df_port_comp para as empresas (tickers)\n",
    "df_peso_long_single_names = df_port_comp_tickers.div(n_series, axis=0)\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame resultante\n",
    "print(\"Resultado do df_peso_long_single_names:\")\n",
    "print(df_peso_long_single_names.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f0de6",
   "metadata": {},
   "source": [
    "Posição Short Single Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6421abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_peso_short_ibov:\n",
      "            peso_short_ibov\n",
      "Data                       \n",
      "2019-09-02             -0.0\n",
      "2019-09-03             -0.0\n",
      "2019-09-04             -0.0\n",
      "2019-09-05             -0.0\n",
      "2019-09-06             -0.0\n",
      "\n",
      "Resultado do df_peso_short_smal:\n",
      "            peso_short_smal\n",
      "Data                       \n",
      "2019-09-02             -0.0\n",
      "2019-09-03             -0.0\n",
      "2019-09-04             -0.0\n",
      "2019-09-05             -0.0\n",
      "2019-09-06             -0.0\n",
      "Tabela salva em posicoes_Ibov.xlsx\n",
      "Tabela salva em posicoes_Smal.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verificações iniciais\n",
    "if 'df_gross_long_novo' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_gross_long_novo' não foi definido.\")\n",
    "if 'df_peso_combinado' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_peso_combinado' não foi definido.\")\n",
    "if 'peso_indices' not in globals():\n",
    "    raise Exception(\"A variável 'peso_indices' não foi definida.\")\n",
    "if 'Peso IBOV' not in df_peso_combinado.columns:\n",
    "    raise Exception(\"A coluna 'Peso IBOV' não foi encontrada em df_peso_combinado.\")\n",
    "if 'Peso SMAL' not in df_peso_combinado.columns:\n",
    "    raise Exception(\"A coluna 'Peso SMAL' não foi encontrada em df_peso_combinado.\")\n",
    "\n",
    "# Cálculo para IBOV\n",
    "produto_ibov = df_gross_long_novo['gross_long_novo'] * df_peso_combinado['Peso IBOV']\n",
    "df_peso_short_ibov = -produto_ibov * peso_indices\n",
    "df_peso_short_ibov = pd.DataFrame(df_peso_short_ibov, columns=['peso_short_ibov'])\n",
    "\n",
    "# Cálculo para SMAL\n",
    "produto_smal = df_gross_long_novo['gross_long_novo'] * df_peso_combinado['Peso SMAL']\n",
    "df_peso_short_smal = -produto_smal * peso_indices\n",
    "df_peso_short_smal = pd.DataFrame(df_peso_short_smal, columns=['peso_short_smal'])\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"Resultado do df_peso_short_ibov:\")\n",
    "print(df_peso_short_ibov.head())\n",
    "\n",
    "print(\"\\nResultado do df_peso_short_smal:\")\n",
    "print(df_peso_short_smal.head())\n",
    "\n",
    "# --- salvar a tabela em Excel ---------------------------------\n",
    "caminho_arquivo_ibov = \"posicoes_Ibov.xlsx\"          # nome do arquivo\n",
    "df_peso_short_ibov.to_excel(\n",
    "    caminho_arquivo_ibov,           # destino\n",
    "    sheet_name=\"PosicoesIbov\",  # nome da aba\n",
    "    index=True                 # mantém a coluna‑índice “Data”\n",
    ")\n",
    "\n",
    "print(f\"Tabela salva em {caminho_arquivo_ibov}\")\n",
    "\n",
    "# --- salvar a tabela em Excel ---------------------------------\n",
    "caminho_arquivo_smal = \"posicoes_Smal.xlsx\"          # nome do arquivo\n",
    "df_peso_short_smal.to_excel(\n",
    "    caminho_arquivo_smal,           # destino\n",
    "    sheet_name=\"PosicoesSmal\",  # nome da aba\n",
    "    index=True                 # mantém a coluna‑índice “Data”\n",
    ")\n",
    "\n",
    "print(f\"Tabela salva em {caminho_arquivo_smal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cf3d90bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe com índice corrigido. Aqui estão as primeiras linhas:\n",
      "            TGMA3  ARML3  VAMO3  ALPA4  AZZA3  ASAI3  CEAB3  CRFB3  ESPA3  \\\n",
      "Data                                                                        \n",
      "2019-09-02      0      0      0      1      1      0      0      0      0   \n",
      "2019-09-03      0      0      0      1      1      0      0      0      0   \n",
      "2019-09-04      0      0      0      1      1      0      0      0      0   \n",
      "2019-09-05      0      0      0      1      1      0      0      0      0   \n",
      "2019-09-06      0      0      0      1      1      0      0      0      0   \n",
      "\n",
      "            GGPS3  ...  TAEE11  ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data               ...                                                      \n",
      "2019-09-02      0  ...       0       0      0      1      0      0      0   \n",
      "2019-09-03      0  ...       0       0      0      1      0      0      0   \n",
      "2019-09-04      0  ...       0       0      0      1      0      0      0   \n",
      "2019-09-05      0  ...       0       0      0      1      0      0      0   \n",
      "2019-09-06      0  ...       0       0      0      1      0      0      0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  \n",
      "Data                             \n",
      "2019-09-02      0      0      0  \n",
      "2019-09-03      0      0      0  \n",
      "2019-09-04      0      0      0  \n",
      "2019-09-05      0      0      0  \n",
      "2019-09-06      0      0      0  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importar o arquivo\n",
    "df_bottom_comp = pd.read_excel('bottom_comp.xlsx', index_col=0)\n",
    "\n",
    "# Assumindo que df_peso_short_small já está disponível no seu código\n",
    "# Podemos copiar o índice diretamente\n",
    "df_bottom_comp.index = df_peso_short_smal.index.copy()\n",
    "\n",
    "# Verificar o resultado\n",
    "print(\"Dataframe com índice corrigido. Aqui estão as primeiras linhas:\")\n",
    "print(df_bottom_comp.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "19a16703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado do df_peso_short_single_names:\n",
      "            TGMA3  ARML3  VAMO3     ALPA4     AZZA3  ASAI3  CEAB3  CRFB3  \\\n",
      "Data                                                                       \n",
      "2019-09-02   -0.0   -0.0   -0.0 -0.038462 -0.038462   -0.0   -0.0   -0.0   \n",
      "2019-09-03   -0.0   -0.0   -0.0 -0.038462 -0.038462   -0.0   -0.0   -0.0   \n",
      "2019-09-04   -0.0   -0.0   -0.0 -0.038462 -0.038462   -0.0   -0.0   -0.0   \n",
      "2019-09-05   -0.0   -0.0   -0.0 -0.038462 -0.038462   -0.0   -0.0   -0.0   \n",
      "2019-09-06   -0.0   -0.0   -0.0 -0.038462 -0.038462   -0.0   -0.0   -0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...  TAEE11  ALUP11  AZUL4     UNIP6  ORVR3  AMBP3  \\\n",
      "Data                      ...                                                  \n",
      "2019-09-02   -0.0   -0.0  ...    -0.0    -0.0   -0.0 -0.038462   -0.0   -0.0   \n",
      "2019-09-03   -0.0   -0.0  ...    -0.0    -0.0   -0.0 -0.038462   -0.0   -0.0   \n",
      "2019-09-04   -0.0   -0.0  ...    -0.0    -0.0   -0.0 -0.038462   -0.0   -0.0   \n",
      "2019-09-05   -0.0   -0.0  ...    -0.0    -0.0   -0.0 -0.038462   -0.0   -0.0   \n",
      "2019-09-06   -0.0   -0.0  ...    -0.0    -0.0   -0.0 -0.038462   -0.0   -0.0   \n",
      "\n",
      "            CVCB3  TASA4  GOLL4  EMBR3  \n",
      "Data                                    \n",
      "2019-09-02   -0.0   -0.0   -0.0   -0.0  \n",
      "2019-09-03   -0.0   -0.0   -0.0   -0.0  \n",
      "2019-09-04   -0.0   -0.0   -0.0   -0.0  \n",
      "2019-09-05   -0.0   -0.0   -0.0   -0.0  \n",
      "2019-09-06   -0.0   -0.0   -0.0   -0.0  \n",
      "\n",
      "[5 rows x 171 columns]\n",
      "\n",
      "Resultado do df_verifica_peso_short_single_names:\n",
      "            soma_verificacao\n",
      "Data                        \n",
      "2019-09-02              -1.0\n",
      "2019-09-03              -1.0\n",
      "2019-09-04              -1.0\n",
      "2019-09-05              -1.0\n",
      "2019-09-06              -1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verifica se os DataFrames e variáveis necessários estão definidos\n",
    "if 'df_port_comp' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_port_comp' não foi definido.\")\n",
    "if 'df_bottom_comp' not in globals():\n",
    "    raise Exception(\"O DataFrame 'df_bottom_comp' não foi definido.\")\n",
    "if 'peso_single_names' not in globals():\n",
    "    raise Exception(\"A variável 'peso_single_names' não foi definida.\")\n",
    "if 'tickers' not in globals():\n",
    "    raise Exception(\"A lista de tickers não foi definida.\")\n",
    "\n",
    "# Seleciona apenas as colunas dos tickers de df_port_comp para garantir a consistência\n",
    "df_port_comp_tickers = df_port_comp[tickers].copy()\n",
    "\n",
    "# Calcula n: a soma, para cada dia, dos valores dos tickers em df_port_comp\n",
    "n_series = df_port_comp_tickers.sum(axis=1)\n",
    "\n",
    "# Aplica a fórmula:\n",
    "# (-100%/n * df_bottom_comp) * peso_single_names\n",
    "# Sabendo que 100% equivale a 1, a expressão fica: (-1/n * df_bottom_comp) * peso_single_names\n",
    "df_peso_short_single_names = df_bottom_comp.mul(-1 / n_series, axis=0) * peso_single_names\n",
    "\n",
    "# Cria um DataFrame de verificação, que contém a soma das linhas de df_peso_short_single_names\n",
    "df_verifica_peso_short_single_names = pd.DataFrame(df_peso_short_single_names.sum(axis=1),\n",
    "                                                   columns=['soma_verificacao'])\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"Resultado do df_peso_short_single_names:\")\n",
    "print(df_peso_short_single_names.head())\n",
    "\n",
    "print(\"\\nResultado do df_verifica_peso_short_single_names:\")\n",
    "print(df_verifica_peso_short_single_names.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0000e",
   "metadata": {},
   "source": [
    "Peso Long Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0e19484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.020947  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-03  0.020953  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-04  0.020938  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-05  0.020865  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-06  0.020659  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "...              ...       ...    ...    ...    ...    ...       ...    ...   \n",
      "2025-03-25  0.022877  0.022877    0.0    0.0    0.0    0.0  0.022877    0.0   \n",
      "2025-03-26  0.022851  0.022851    0.0    0.0    0.0    0.0  0.022851    0.0   \n",
      "2025-03-27  0.022849  0.022849    0.0    0.0    0.0    0.0  0.022849    0.0   \n",
      "2025-03-28  0.022837  0.022837    0.0    0.0    0.0    0.0  0.022837    0.0   \n",
      "2025-03-31  0.022821  0.022821    0.0    0.0    0.0    0.0  0.022821    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data                      ...                                                \n",
      "2019-09-02    0.0    0.0  ...  0.020947    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0  ...  0.020953    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0  ...  0.020938    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0  ...  0.020865    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0  ...  0.020659    0.0    0.0    0.0    0.0    0.0   \n",
      "...           ...    ...  ...       ...    ...    ...    ...    ...    ...   \n",
      "2025-03-25    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-26    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-27    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-28    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-31    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  Soma_verificacao  \n",
      "Data                                               \n",
      "2019-09-02    0.0    0.0    0.0               1.0  \n",
      "2019-09-03    0.0    0.0    0.0               1.0  \n",
      "2019-09-04    0.0    0.0    0.0               1.0  \n",
      "2019-09-05    0.0    0.0    0.0               1.0  \n",
      "2019-09-06    0.0    0.0    0.0               1.0  \n",
      "...           ...    ...    ...               ...  \n",
      "2025-03-25    0.0    0.0    0.0               1.0  \n",
      "2025-03-26    0.0    0.0    0.0               1.0  \n",
      "2025-03-27    0.0    0.0    0.0               1.0  \n",
      "2025-03-28    0.0    0.0    0.0               1.0  \n",
      "2025-03-31    0.0    0.0    0.0               1.0  \n",
      "\n",
      "[1456 rows x 172 columns]\n",
      "            peso_short_ibov\n",
      "Data                       \n",
      "2019-09-02             -0.0\n",
      "2019-09-03             -0.0\n",
      "2019-09-04             -0.0\n",
      "2019-09-05             -0.0\n",
      "2019-09-06             -0.0\n",
      "...                     ...\n",
      "2025-03-25             -0.0\n",
      "2025-03-26             -0.0\n",
      "2025-03-27             -0.0\n",
      "2025-03-28             -0.0\n",
      "2025-03-31             -0.0\n",
      "\n",
      "[1456 rows x 1 columns]\n",
      "            peso_short_smal\n",
      "Data                       \n",
      "2019-09-02             -0.0\n",
      "2019-09-03             -0.0\n",
      "2019-09-04             -0.0\n",
      "2019-09-05             -0.0\n",
      "2019-09-06             -0.0\n",
      "...                     ...\n",
      "2025-03-25             -0.0\n",
      "2025-03-26             -0.0\n",
      "2025-03-27             -0.0\n",
      "2025-03-28             -0.0\n",
      "2025-03-31             -0.0\n",
      "\n",
      "[1456 rows x 1 columns]\n",
      "               TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.033645  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-03  0.033563  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-04  0.033692  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-05  0.033625  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-06  0.033571  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "...              ...       ...    ...    ...    ...    ...       ...    ...   \n",
      "2025-03-25  0.025404  0.024392    0.0    0.0    0.0    0.0  0.025355    0.0   \n",
      "2025-03-26  0.025274  0.024393    0.0    0.0    0.0    0.0  0.025458    0.0   \n",
      "2025-03-27  0.025297  0.024439    0.0    0.0    0.0    0.0  0.025564    0.0   \n",
      "2025-03-28  0.025328  0.024010    0.0    0.0    0.0    0.0  0.025512    0.0   \n",
      "2025-03-31  0.025422  0.023881    0.0    0.0    0.0    0.0  0.025426    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  CVCB3  \\\n",
      "Data                      ...                                                \n",
      "2019-09-02    0.0    0.0  ...  0.045386    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0  ...  0.045317    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0  ...  0.045655    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0  ...  0.045774    0.0    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0  ...  0.045842    0.0    0.0    0.0    0.0    0.0   \n",
      "...           ...    ...  ...       ...    ...    ...    ...    ...    ...   \n",
      "2025-03-25    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-26    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-27    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-28    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "2025-03-31    0.0    0.0  ...  0.000000    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            TASA4  GOLL4  EMBR3  Soma_verificacao  \n",
      "Data                                               \n",
      "2019-09-02    0.0    0.0    0.0               1.0  \n",
      "2019-09-03    0.0    0.0    0.0               1.0  \n",
      "2019-09-04    0.0    0.0    0.0               1.0  \n",
      "2019-09-05    0.0    0.0    0.0               1.0  \n",
      "2019-09-06    0.0    0.0    0.0               1.0  \n",
      "...           ...    ...    ...               ...  \n",
      "2025-03-25    0.0    0.0    0.0               1.0  \n",
      "2025-03-26    0.0    0.0    0.0               1.0  \n",
      "2025-03-27    0.0    0.0    0.0               1.0  \n",
      "2025-03-28    0.0    0.0    0.0               1.0  \n",
      "2025-03-31    0.0    0.0    0.0               1.0  \n",
      "\n",
      "[1456 rows x 172 columns]\n",
      "               TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-03  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-04  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-05  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-06  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "...              ...       ...    ...    ...    ...    ...       ...    ...   \n",
      "2025-03-25  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-26  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-27  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-28  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-31  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    TAEE11    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  \\\n",
      "Data                      ...                                                   \n",
      "2019-09-02    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "...           ...    ...  ...       ...       ...    ...    ...    ...    ...   \n",
      "2025-03-25    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-26    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-27    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-28    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-31    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            CVCB3  TASA4  GOLL4  EMBR3  \n",
      "Data                                    \n",
      "2019-09-02    0.0    0.0    0.0    0.0  \n",
      "2019-09-03    0.0    0.0    0.0    0.0  \n",
      "2019-09-04    0.0    0.0    0.0    0.0  \n",
      "2019-09-05    0.0    0.0    0.0    0.0  \n",
      "2019-09-06    0.0    0.0    0.0    0.0  \n",
      "...           ...    ...    ...    ...  \n",
      "2025-03-25    0.0    0.0    0.0    0.0  \n",
      "2025-03-26    0.0    0.0    0.0    0.0  \n",
      "2025-03-27    0.0    0.0    0.0    0.0  \n",
      "2025-03-28    0.0    0.0    0.0    0.0  \n",
      "2025-03-31    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[1456 rows x 171 columns]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df_long_indices_ibov)\n",
    "print(df_peso_short_ibov)\n",
    "print(df_peso_short_smal)\n",
    "print(df_long_indices_smal)\n",
    "print(df_peso_long_single_names)\n",
    "print(peso_single_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2dca2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TGMA3     ARML3  VAMO3  ALPA4  AZZA3  ASAI3     CEAB3  CRFB3  \\\n",
      "Data                                                                          \n",
      "2019-09-02  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-03  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-04  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-05  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "2019-09-06  0.038462  0.000000    0.0    0.0    0.0    0.0  0.000000    0.0   \n",
      "...              ...       ...    ...    ...    ...    ...       ...    ...   \n",
      "2025-03-25  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-26  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-27  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-28  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "2025-03-31  0.028571  0.028571    0.0    0.0    0.0    0.0  0.028571    0.0   \n",
      "\n",
      "            ESPA3  GGPS3  ...    TAEE11    ALUP11  AZUL4  UNIP6  ORVR3  AMBP3  \\\n",
      "Data                      ...                                                   \n",
      "2019-09-02    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-03    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-04    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-05    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "2019-09-06    0.0    0.0  ...  0.038462  0.038462    0.0    0.0    0.0    0.0   \n",
      "...           ...    ...  ...       ...       ...    ...    ...    ...    ...   \n",
      "2025-03-25    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-26    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-27    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-28    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "2025-03-31    0.0    0.0  ...  0.028571  0.000000    0.0    0.0    0.0    0.0   \n",
      "\n",
      "            CVCB3  TASA4  GOLL4  EMBR3  \n",
      "Data                                    \n",
      "2019-09-02    0.0    0.0    0.0    0.0  \n",
      "2019-09-03    0.0    0.0    0.0    0.0  \n",
      "2019-09-04    0.0    0.0    0.0    0.0  \n",
      "2019-09-05    0.0    0.0    0.0    0.0  \n",
      "2019-09-06    0.0    0.0    0.0    0.0  \n",
      "...           ...    ...    ...    ...  \n",
      "2025-03-25    0.0    0.0    0.0    0.0  \n",
      "2025-03-26    0.0    0.0    0.0    0.0  \n",
      "2025-03-27    0.0    0.0    0.0    0.0  \n",
      "2025-03-28    0.0    0.0    0.0    0.0  \n",
      "2025-03-31    0.0    0.0    0.0    0.0  \n",
      "\n",
      "[1456 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Função para criar o df_peso_long_final\n",
    "def criar_df_peso_long_final(df_peso_short_ibov, df_long_indices_ibov, \n",
    "                            df_peso_short_smal, df_long_indices_smal, \n",
    "                            df_peso_long_single_names, peso_single_names, tickers):\n",
    "    \"\"\"\n",
    "    Cria df_peso_long_final usando a fórmula:\n",
    "    = -df_peso_short_ibov * df_long_indices_ibov - df_peso_short_smal * df_long_indices_smal + peso_single_names * df_peso_long_single_names\n",
    "    \"\"\"\n",
    "    # Inicializar dataframe final com as mesmas datas dos dataframes de entrada\n",
    "    df_peso_long_final = pd.DataFrame(index=df_peso_short_ibov.index, columns=tickers)\n",
    "    \n",
    "    # Para cada ticker na lista de tickers comuns\n",
    "    for ticker in tickers:\n",
    "        # Aplicar a fórmula para este ticker\n",
    "        # Multiplicação do peso short IBOV pelo long indices IBOV\n",
    "        termo1 = -df_peso_short_ibov.values * df_long_indices_ibov[ticker].values\n",
    "        \n",
    "        # Multiplicação do peso short SMAL pelo long indices SMAL\n",
    "        termo2 = -df_peso_short_smal.values * df_long_indices_smal[ticker].values\n",
    "        \n",
    "        # Multiplicação do peso_single_names pelo peso long single names\n",
    "        termo3 = peso_single_names * df_peso_long_single_names[ticker].values\n",
    "        \n",
    "        # Somar os termos e atribuir ao ticker correspondente no dataframe final\n",
    "        df_peso_long_final[ticker] = termo1.flatten() + termo2.flatten() + termo3\n",
    "    \n",
    "    # Adicionar coluna de soma para verificação\n",
    "    df_peso_long_final['soma'] = df_peso_long_final[tickers].sum(axis=1)\n",
    "    \n",
    "    return df_peso_long_final\n",
    "\n",
    "# Exemplo de uso do código\n",
    "# Assumindo que você já tenha os dataframes carregados e a lista de tickers definida:\n",
    "\n",
    "\"\"\"\n",
    "# Exemplo:\n",
    "# tickers = ['PETR4', 'VALE3', 'ITUB4', ...]  # Lista de tickers comuns\n",
    "\n",
    "df_peso_long_final = criar_df_peso_long_final(\n",
    "    df_peso_short_ibov,  # DataFrame com apenas uma coluna de valores para cada data\n",
    "    df_long_indices_ibov,  # DataFrame com colunas para cada ticker\n",
    "    df_peso_short_smal,  # DataFrame com apenas uma coluna de valores para cada data \n",
    "    df_long_indices_smal,  # DataFrame com colunas para cada ticker\n",
    "    df_peso_long_single_names,  # DataFrame com colunas para cada ticker\n",
    "    peso_single_names,  # Valor escalar\n",
    "    tickers  # Lista de tickers comuns\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Se você precisar de uma versão ainda mais vetorizada:\n",
    "def criar_df_peso_long_final_v2(df_peso_short_ibov, df_long_indices_ibov, \n",
    "                              df_peso_short_smal, df_long_indices_smal, \n",
    "                              df_peso_long_single_names, peso_single_names, tickers):\n",
    "    \"\"\"\n",
    "    Versão totalmente vetorizada da função\n",
    "    \"\"\"\n",
    "    # Filtrar apenas os tickers necessários\n",
    "    df_long_indices_ibov_filtered = df_long_indices_ibov[tickers]\n",
    "    df_long_indices_smal_filtered = df_long_indices_smal[tickers]\n",
    "    df_peso_long_single_names_filtered = df_peso_long_single_names[tickers]\n",
    "    \n",
    "    # Converter os pesos de short para um formato adequado para broadcast\n",
    "    peso_short_ibov = df_peso_short_ibov.values.reshape(-1, 1)\n",
    "    peso_short_smal = df_peso_short_smal.values.reshape(-1, 1)\n",
    "    \n",
    "    # Aplicar a fórmula de uma só vez\n",
    "    df_peso_long_final = (\n",
    "        -peso_short_ibov * df_long_indices_ibov_filtered\n",
    "        -peso_short_smal * df_long_indices_smal_filtered\n",
    "        +peso_single_names * df_peso_long_single_names_filtered\n",
    "    )\n",
    "    \n",
    "    # Adicionar coluna de soma\n",
    "    \n",
    "    \n",
    "    return df_peso_long_final\n",
    "\n",
    "df_peso_long_final = criar_df_peso_long_final_v2(df_peso_short_ibov, df_long_indices_ibov, \n",
    "                              df_peso_short_smal, df_long_indices_smal, \n",
    "                              df_peso_long_single_names, peso_single_names, tickers)\n",
    "\n",
    "print(df_peso_long_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8ccd7491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TGMA3     ARML3  VAMO3     ALPA4     AZZA3  ASAI3     CEAB3  \\\n",
      "Data                                                                         \n",
      "2019-09-02  0.038462  0.000000    0.0 -0.038462 -0.038462    0.0  0.000000   \n",
      "2019-09-03  0.038462  0.000000    0.0 -0.038462 -0.038462    0.0  0.000000   \n",
      "2019-09-04  0.038462  0.000000    0.0 -0.038462 -0.038462    0.0  0.000000   \n",
      "2019-09-05  0.038462  0.000000    0.0 -0.038462 -0.038462    0.0  0.000000   \n",
      "2019-09-06  0.038462  0.000000    0.0 -0.038462 -0.038462    0.0  0.000000   \n",
      "...              ...       ...    ...       ...       ...    ...       ...   \n",
      "2025-03-25  0.028571  0.028571    0.0  0.000000 -0.028571    0.0  0.028571   \n",
      "2025-03-26  0.028571  0.028571    0.0  0.000000 -0.028571    0.0  0.028571   \n",
      "2025-03-27  0.028571  0.028571    0.0  0.000000 -0.028571    0.0  0.028571   \n",
      "2025-03-28  0.028571  0.028571    0.0  0.000000 -0.028571    0.0  0.028571   \n",
      "2025-03-31  0.028571  0.028571    0.0  0.000000 -0.028571    0.0  0.028571   \n",
      "\n",
      "               CRFB3  ESPA3  GGPS3  ...    TAEE11    ALUP11  AZUL4     UNIP6  \\\n",
      "Data                                ...                                        \n",
      "2019-09-02  0.000000    0.0    0.0  ...  0.038462  0.038462    0.0 -0.038462   \n",
      "2019-09-03  0.000000    0.0    0.0  ...  0.038462  0.038462    0.0 -0.038462   \n",
      "2019-09-04  0.000000    0.0    0.0  ...  0.038462  0.038462    0.0 -0.038462   \n",
      "2019-09-05  0.000000    0.0    0.0  ...  0.038462  0.038462    0.0 -0.038462   \n",
      "2019-09-06  0.000000    0.0    0.0  ...  0.038462  0.038462    0.0 -0.038462   \n",
      "...              ...    ...    ...  ...       ...       ...    ...       ...   \n",
      "2025-03-25 -0.028571    0.0    0.0  ...  0.028571 -0.028571    0.0 -0.028571   \n",
      "2025-03-26 -0.028571    0.0    0.0  ...  0.028571 -0.028571    0.0 -0.028571   \n",
      "2025-03-27 -0.028571    0.0    0.0  ...  0.028571 -0.028571    0.0 -0.028571   \n",
      "2025-03-28 -0.028571    0.0    0.0  ...  0.028571 -0.028571    0.0 -0.028571   \n",
      "2025-03-31 -0.028571    0.0    0.0  ...  0.028571 -0.028571    0.0 -0.028571   \n",
      "\n",
      "            ORVR3  AMBP3  CVCB3  TASA4  GOLL4     EMBR3  \n",
      "Data                                                     \n",
      "2019-09-02    0.0    0.0    0.0    0.0    0.0  0.000000  \n",
      "2019-09-03    0.0    0.0    0.0    0.0    0.0  0.000000  \n",
      "2019-09-04    0.0    0.0    0.0    0.0    0.0  0.000000  \n",
      "2019-09-05    0.0    0.0    0.0    0.0    0.0  0.000000  \n",
      "2019-09-06    0.0    0.0    0.0    0.0    0.0  0.000000  \n",
      "...           ...    ...    ...    ...    ...       ...  \n",
      "2025-03-25    0.0    0.0    0.0    0.0    0.0 -0.028571  \n",
      "2025-03-26    0.0    0.0    0.0    0.0    0.0 -0.028571  \n",
      "2025-03-27    0.0    0.0    0.0    0.0    0.0 -0.028571  \n",
      "2025-03-28    0.0    0.0    0.0    0.0    0.0 -0.028571  \n",
      "2025-03-31    0.0    0.0    0.0    0.0    0.0 -0.028571  \n",
      "\n",
      "[1456 rows x 171 columns]\n",
      "Tabela salva em posicoes_net.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_posicoes_net = (df_peso_long_final +df_peso_short_single_names )\n",
    "\n",
    "print(df_posicoes_net)\n",
    "\n",
    "# --- salvar a tabela em Excel ---------------------------------\n",
    "caminho_arquivo_posicoes = \"posicoes_net.xlsx\"          # nome do arquivo\n",
    "df_posicoes_net.to_excel(\n",
    "    caminho_arquivo_posicoes,           # destino\n",
    "    sheet_name=\"PosicoesNet\",  # nome da aba\n",
    "    index=True                 # mantém a coluna‑índice “Data”\n",
    ")\n",
    "\n",
    "print(f\"Tabela salva em {caminho_arquivo_posicoes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
